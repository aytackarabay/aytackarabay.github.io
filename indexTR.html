<!DOCTYPE html>
<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Aytac Karabay</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="owwwlab.com">
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
        
        <meta name="description" content="Aytac Karabay personal webpage" />
        <meta name="keywords" content="faculty profile, theme,css, html, jquery, transition, transform, 3d, css3" />

        <link rel="shortcut icon" href="favicon.ico">
		

        <!--CSS styles-->
        <link rel="stylesheet" href="css/bootstrap.css">
        <link rel="stylesheet" href="css/font-awesome.min.css">  
        <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
        <link rel="stylesheet" href="css/magnific-popup.css">
        <link rel="stylesheet" href="css/style.css">
        <link id="theme-style" rel="stylesheet" href="css/theme-style.css">
		<link href="https://fonts.googleapis.com/css?family=Open+Sans&amp;subset=latin-ext" rel="stylesheet">
        
        <!--/CSS styles-->
        <!--Javascript files-->
        <script type="text/javascript" src="js/jquery-1.10.2.js"></script>
        <script type="text/javascript" src="js/TweenMax.min.js"></script>
        <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
        <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>
        
        <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
        <script type="text/javascript" src="js/jquery.dropdownit.js"></script>

        <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
        <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>

        <script type="text/javascript" src="js/bootstrap.min.js"></script>

        <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>

        <script type="text/javascript" src="js/masonry.min.js"></script>

        <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>

        <script type="text/javascript" src="js/magnific-popup.js"></script>
        <script type="text/javascript" src="js/custom.js"></script>

        <!--/Javascript files-->

    </head>
    <body>
		
        <div id="wrapper">
            <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a>

            <div id="sidebar">
                <div id="main-nav">
                    <div id="nav-container">
                        <div id="profile" class="clearfix">
                            <div class="portrate hidden-xs"></div>
                            
                        </div>
                        <ul id="navigation">
                            <li>
                              <a href="#biography">
                                <div class="icon icon-user"></div>
                                <div class="text">Hakkımda</div>
                              </a>
                            </li>  
                            
                            <li>
                              <a href="#research">
                                <div class="icon icon-book"></div>
                                <div class="text">Blog</div>
                              </a>
                            </li> 
                            
                            <li>
                              <a href="#publications">
                                <div class="icon icon-edit"></div>
                                <div class="text">Yayınlar</div>
                              </a>
                            </li> 
							
							<li>
                              <a href="#experiments">
                                <div class="icon icon-bullseye"></div>
                                <div class="text">Görevler</div>
                              </a>
                            </li> 
                            <!--<li>
                              <a href="#teaching">
                                <div class="icon icon-time"></div>
                                <div class="text">Teaching</div>
                              </a>
                            </li>-->

                            <!--<li>
                              <a href="#gallery">
                                <div class="icon icon-picture"></div>
                                <div class="text">Gallery</div>
                              </a>
                            </li>-->

                            <li class="external">
                              <a target="_blank" href="#">
                                  <div class="icon icon-download-alt"></div>
                                  <div class="text"><a href="Files/download/Resume_Karabay.pdf" target="_blank">CV</a></div>
                              </a>
                            </li>
							
							<li>
                              <a href="#contact">
                                  <div class="icon icon-calendar"></div>
                                  <div class="text">İletişim</div>
                              </a>
                            </li>
                        </ul>
                    </div>        
                </div>
                
                <div class="social-icons">
                    <!--<ul>
                        <li><a href="#"><i class="icon-facebook"></i></a></li>
                        <li><a href="#"><i class="icon-twitter"></i></a></li>
                        <li><a href="#"><i class="icon-linkedin"></i></a></li>
                    </ul>-->
                </div>    
            </div>

            <div id="main">
		        <div id="biography" class="page home" data-pos="home">
							<div class="row2">
								<div id="rightlinks">
									<a href="indexTR.html">TR</a> 
									<a href="index.html">EN</a> 
								</div>	
							</div>
							   
					<!--<div class="section color-2">
                        <div class="section-container2">
                                 
                        </div>
                    </div>-->
					
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
								
								
                                
                                <div class="row">
                                    <div class="col-sm-2 visible-sm"></div>
									<div class="clearfix visible-sm visible-xs"></div>
                                    <div class="col-sm-12 col-md-10">
										<h3 class="title">Biyografi</h3>
										<div class="col-sm-8 col-md-5">
                                        <div class="biothumb">
                                            <img alt="image" src="img/personal/personal-big.jpg" class="img-responsive">
                                            <div class="overlay">
											                                                
                                                <h3 class="">Aytaç Karabay, PhD</h3>
                                                <ul class="list-unstyled">
                                                    <li>Bilişsel Psikoloji</li>
                                                    <li>New York Üniversitesi Abu Dhabi</li>
                                                </ul>
                                            </div> 
                                         </div>
										</div>
                                        Ben <b>Aytaç Karabay (1989),</b> New York Üniversitesi Abu Dhabi kampüsünde bilişsel nörobilim alanında doktora sonrası araştırmacı 
										olarak çalışmaları sürdürmekteyim. 2007 ve 2011 yılları arasında Ankara Üniversitesinde psikoloji alanında lisans 
										eğitimimi tamamladım. Lisans eğitimim bittikten sonra bir yıl kadar çeşitli kurumlarda psikolog olarak görev yaptım. 
										2013 yılında, yüksek lisans eğitimime Brooklyn College, CUNY’de başladım.
										<a href="https://www.gc.cuny.edu/people/daniel-kurylo" target="_blank">Daniel Kurylo</a>’nun
										görsel algıyı araştırdığı hayvan labaratuvarında gönüllü labaratuvar asistanı olarak bir yıl çalıştım ve yüksek
										lisansımı “Yön Uyumu ile Algısal Gruplama (Perceptual Grouping by Orientation Coherence)” tezi ile 2015 yılında tamamladım.
										2015 ve 2020 yılları arasında Groningen Üniversitesinde doktoramı prof. 
										<a href="https://www.elkanakyurek.com/" target="_blank">Elkan Akyürek</a>’in danışmanlığı altında "Uyarıcıdan İmgeye 
										(From Stimulus to Representation)" adlı doktora tezi ile tamamladım. Doktoramdan sonra ilk doktora sonrası araştırmacı pozisyonumu
										NWO - Open Research Area Fonunun desteklediği doktora sonrası araştırmalarımda çalışma belleğinin gizil süreçlerini EEG aracılığı 
										ile araştırdım. Şu anda <a href="https://sites.google.com/site/fougnielab/home" target="_blank">Daryl Fougnie</a>’in danışmanlığında
										doktora sonrası araştırmalarıma New York Üniversitesinde devam etmekteyim.
										</div> 
								</div>
                            </div>        
                        </div>
                    </div>
					
					<div class="pagecontents">
							<div class="section color-2">
							<div class="section-container">
							<div class="row">
									<div class="col-md-9 col-md-offset-1">
                                    <div class="title text-center">
                                        <h2>İlgi alanları</h2>
                                    </div>
									</div>
									<div class="col-md-5">
                                        <ul class="ul-boxed list-unstyled" data-columns="2">
                                            <li>Görsel Dikkat</li>
                                            <li>Görsel Algı</li>
                                            <li>Görsel Çalışma Belleği</li>											
                                        </ul>
									</div>
									<div class="col-md-5 col-md-offset-1">
                                        <ul class="ul-boxed list-unstyled" data-columns="2">
											<li>Zamansal Birleştirme</li>
                                            <li>Algısal Gruplama</li>
                                            <li>Kakao Flavanolları</li>
                                        </ul>
									</div>
							</div>
							</div>
							</div>
					</div>
					
                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
									<div class="col-md-5">
                                        <div class="title text-center">
                                            <h2>Eğitim</h2>
                                        </div>
                                        <ul class="ul-dates">
                                            <li>
                                                <div class="dates">
                                                    <span>Ph.D.</span>
                                                    <span>2020</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Bilişsel Nörobilim</h4>
                                                    <p><em>University of Groningen,</em> Groningen, Hollanda</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dates">
                                                    <span>M.A.</span>
													<span>2015</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Deneysel Psikoloji</h4>
                                                    <p><em>Brooklyn College, City University of New York,</em> NY, ABD</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dates">
                                                    <span>B.A.</span>
													<span>2011</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Psikoloji</h4>
                                                    <p><em>Ankara Universitesi,</em> Ankara, Türkiye</p>
                                                </div>
                                            </li>
                                            
                                        </ul>
                                    </div> 
                                    <div class="col-md-5 col-md-offset-1">
                                        <div class="title text-center">
                                            <h2>Akademik Pozisyonlar</h2>
                                        </div>
                                        <ul class="ul-dates">
											<li>
                                                <div class="dates">
                                                    <span>2022</span>
                                                    <span>2025</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Doktora Sonrası Araştırmacı</h4>
                                                    <p>New York University</p>
                                                </div>
                                            </li>
											<li>
                                                <div class="dates">
                                                    <span>2019</span>
                                                    <span>2022</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Doktora Sonrası Araştırmacı</h4>
                                                    <p>Rijksuniversiteit Groningen</p>
                                                </div>
                                            </li>
                                            <li>
                                                <div class="dates">
                                                    <span>2014</span>
                                                    <span>2015</span>
                                                </div>
                                                <div class="content">
                                                    <h4>Labaratuvar Asistanı</h4>
                                                    <p><em>Animal vision lab</em>, Brooklyn College, CUNY</p>
                                                </div>
                                            </li>
                                        </ul>
                                    </div>   
                                </div>    
                            </div>
                                
                        </div>

                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-10 col-md-offset-1">
                                        <div class="title text-center">
                                            <h2>Burslar ve Ödüller </h2>
                                        </div>
                                        <ul class="timeline">
                                            <li class="open">
                                                <div class="date">2022</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject">Açık bilim ödülü, Open Science Programme, Groningen Üniversitesi</div>
                                                    <div class="text row">
                                                        <div class="col-md-2">
                                                            <img alt="image" class="thumbnail img-responsive" src="img/personal/OPA.jpeg" >
                                                        </div>
                                                        <div class="col-md-10">
                                                           ‘Concealed familiar face detection with pupillometry in rapid serial visual presentation’ çalışmamızdan dolayı Groningen Üniversitesi'nin Open Science Programme departmanı tarafından açık bilim ödülüne layık görüldüm.
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>    
											
											<li class="open">
                                                <div class="date">2022</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject">En iyi poster ödülü, Working Memory Engram workshop</div>
                                                    <div class="text row">
                                                        <div class="col-md-2">
                                                            <img alt="image" class="thumbnail img-responsive" src="img/personal/WM_engram_icon.png" >
                                                        </div>
                                                        <div class="col-md-10">
                                                           Hollanda'da Groningen Üniversitesinde düzenlenen Searching for the Working Memory Engram workshopunda en iyi poster ödülü. 
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>  


											
                                            <li class="open">
                                                <div class="date">2012-2019</div>
                                                <div class="circle"></div>
                                                <div class="data">
                                                    <div class="subject">YLSY-MEB bursu (200.000$)</div>
                                                    <div class="text row">
                                                        <div class="col-md-2">
                                                            <img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
                                                        </div>
                                                        <div class="col-md-10">
                                                           MEB-YLSY bursu, yurtdışında, deneysel psikoloji alanında, master ve doktora programlarını kapsar. 
                                                        </div>
                                                    </div>
                                                </div>
                                            </li>
                                         </ul>
                                    </div>
                                </div>
                            </div>
                        </div>                            
                    </div>
                </div>

                <div id="research" class="page">
					<div class="row2">
						<div id="rightlinks">
							<a href="indexTR.html">TR</a> 
							<a href="index.html">EN</a> 
						</div>	
					</div>
                    <div class="pageheader">
						<div class="headercontent">
							<div class="page-container">
								<div class="section-container">
									<h3 class="title">Blog</h3>
								</div>
								<div class="section color-2">
									<div class="section-container">
										<div class="row">
											<div class="col-md-12">
												<ul class="ul-withdetails">
													<div class="row">
                                                    <div class="col-sm-6 col-md-2">
                                                        <div class="image">
                                                            <img alt="image" src="img/blog/Psychonomics.jpeg" class="img-responsive2">
                                                        </div>
                                                    </div>
                                                    <div class="col-sm-6 col-md-9">
                                                        <div class="meta">
                                                            <h2>Psychonomics Meeting (5/2018)</h2>
                                                            <p> Uluslararasi Psychonomics Toplantısı Groningen`e yakın olan Amsterdam'da gerçekleşti. Ben de bu şansı değerlendirip konferansa emektar posterimle (Target color and contrast influences temporal attention...) katıldım. Çok iyi bir şekilde organize edilmiş olan bu konferansa katılmak çok güzel bir deneyimdi. Aynı zamanda birkaç gece Amsterdam'ın tadını çıkartmak da konferansın yanında ayrıca güzeldi.  </p>
                                                        </div>
                                                    </div>
													</div>
												</ul>
											</div>
										</div>
                                    </div>
                                </div>
								<div class="section color-1">
									<div class="section-container">
										<div class="row">
											<div class="col-md-12">
												<ul class="ul-withdetails">
											<div class="row">
                                                    <div class="col-sm-6 col-md-2">
                                                        <div class="image">
                                                            <img alt="image" src="img/blog/darkchocolate.jpg" class="img-responsive2">
                                                        </div>
                                                    </div>
                                                    <div class="col-sm-6 col-md-9">
                                                        <div class="meta">
                                                            <h2>Mindwise-Blogpost (4/2018)</h2>
                                                            <p>Kakao flavanolları hakkında yazdığımız ve Psychopharmacology dergisinde yayınladığımız makaleyi <a href="https://www.elkanakyurek.com/" target="_blank">Elkan</a> ile birlikte blogpost olarak <a href="http://mindwise-groningen.nl/" target="_blank"> Mindwise</a>’ta yayınladık. Yazının tamamına <a href="http://mindwise-groningen.nl/attention-chocolate-can-give-you-an-edge/" target="_blank"> link</a>ten ulaşabilirsiniz. Bu blogpostu hazırlarken makale hakkında açılmış olan bir <a href="https://www.reddit.com/r/Nootropics/comments/83i3kt/the_acute_effects_of_cocoa_flavanols_on_temporal/" target="_blank"> reddit post</a>una denk geldim. Makalemizin sosyal medyada pozitif bir şekilde tartışılması gerçekten güzel bir his.</p>
                                                        </div>
                                                    </div>
                                            </div>
                                       </ul>
											</div>
										</div>
                                    </div>
                                </div>
							</div>
                        </div>    
                    </div>
                </div>
               <div id="publications" class="page">
					<div class="row2">
						<div id="rightlinks">
							<a href="indexTR.html">TR</a> 
							<a href="index.html">EN</a> 
						</div>	
					</div>
                    <div class="page-container">
                        <div class="pageheader">
                            <div class="headercontent">
                                <div class="section-container">
                                    
                                    <h2 class="title">Yayınlar</h2>
                                                                        
                                </div>
                            </div>
                        </div>

                        <div class="pagecontents">
                            
                            <div class="section color-1" id="filters">
                                <div class="section-container">
                                    <div class="row">
                                        
                                        <div class="col-md-3">
                                            <h3>Türe göre filtrele:</h3>
                                        </div>
                                        <div class="col-md-6">
                                            <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                                                <option class="filter" value="all" selected>Hepsi</option>
                                                <option class="filter" value="jpaper">Makaleler</option>
                                                <option class="filter" value="cpaper">Konferans Sunumları</option>
                                                <!-- <option class="filter" value="bookchapter">Book Chapters</option>-->
                                                <option class="filter" value="book">Kitaplar</option>
                                                <!-- <option class="filter" value="report">Reports</option>
                                                <option class="filter" value="tpaper">Technical Papers</option> -->
                                            </select>
                                        </div>
                                        
                                        <div class="col-md-3" id="sort">
                                            <span>Yıla göre sırala:</span>
                                            <div class="btn-group pull-right"> 

                                                <button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default"><i class="icon-sort-by-order"></i></button>
                                                <button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default"><i class="icon-sort-by-order-alt"></i></button>
                                            </div>
                                        </div>    
                                    </div>
                                </div>
                            </div>

                            <div class="section color-2" id="pub-grid">
                                <div class="section-container">
                                    
                                    <div class="row">
                                        <div class="col-md-12">
                                            <div class="pitems">
												
												<div class="item mix jpaper" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            
                                                            <a href="https://escienceediting.org/journal/view.php?doi=10.6087/kcse.345" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href="https://escienceediting.org/upload/pdf/kcse-345.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<!--<a href="https://osf.io/wf5uv/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> -->
															
													    </div>
                                                        <h4 class="pubtitle">Our journey as intern junior editors at the journal of experimental psychology: Human perception and performance</h4>
                                                        <div class="pubauthor">Guérin, S.M.R., Tarlao, C., & <strong>Karabay, A.</strong></div>
                                                        <div class="pubcite"><span class="label label-success">Essay</span> Science Editing. (2024)</div>
                                                    </div>
                                                </div>		
												
												
												
												
												<div class="item mix jpaper" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <!--<a href="https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00173/120839/Concurrent-maintenance-of-both-veridical-and" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href="https://mitp.silverchair-cdn.com/mitp/content_public/journal/imag/2/10.1162_imag_a_00173/4/imag_a_00173.pdf?Expires=1719313245&Signature=fcaVhFZeb56R3KRu3pamswignixdwtq2mPkVgVL4sTcr4GZ-I7wzSHZCYnD1NOZPnDInbSBhjd~nvMZ9ZN8yWBTFVQLpyicdQmJNLXn0zJDY69np65rkZZW2QrQ98J7JwXfSdc~MPt~3gJkD4KZ2ubdcS4zoY~eicJgdkOSeYgtJJCugSpAOLhh0QNwV70a4FvgVl4j7BikyjnRIF6XhXEOy5yaUD2MjQ85heTiKOoiaccc9-J25yXLmWUBCuuDLezKn7N7tynLBZtvS7drlSqWRrMReP9kgO8KERPAgDQByBn8lA6uVilHj0M73lJLPnKvomogo43H3pgXtgmYzCQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>-->
															<a href="https://osf.io/wf5uv/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
															
													    </div>
                                                        <h4 class="pubtitle">Introducing ART: a new method of testing auditory memory with circular reproduction tasks</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>, Nijenkamp, R., Sarampalis, A., & Fougnie, D. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Behavior Research Methods. (in press)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Theories of visual working memory have seen significant progress through the use of continuous reproduction tasks. However, these tasks have mainly focused on studying visual features, 
														with limited examples existing in the auditory domain. Therefore, it is unknown to what extent newly developed memory models reflect domain-general limitations or are specific to the visual
														domain. To address this gap, we developed a novel methodology: the Auditory Reproduction Task (ART). This task utilizes Shepard tones, which create an infinite rising or falling tone illusion
														by dissecting pitch chroma and height, to create a 1-360° auditory circular space. In Experiment 1, we validated the perceptual circularity and uniformity of this auditory stimulus space. 
														In Experiment 2, we demonstrated that auditory working memory shows similar set size effects to visual working memory—report error increased at set size two relative to one caused by swap errors.
														In Experiment 3, we tested the validity of ART by correlating reproduction errors with commonly used auditory and visual working memory tasks. Analyses revealed that ART errors were significantly
														correlated with performance in both auditory and visual working memory tasks, albeit with a stronger correlation observed with auditory working memory. While these experiments have only scratched
														the surface of the theoretical and computational constraints on auditory working memory, they provide a valuable proof-of-concept for ART. Further research with ART has the potential to deepen
														our understanding of auditory working memory, as well as to explore the extent to which existing models are tapping into domain-general constraints. 
														</p>
                                                    </div>
                                                </div>						
												
												
												<div class="item mix cpaper" data-year="2024">
													<div class="pubmain">
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Evidence against levels of processing theories of visual awareness </h4>
                                                        <div class="pubauthor"> <strong>Karabay, A.</strong>, & Fougnie, D.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>  Asia Pacific Conference On Vision (APCV2024) in Singapore. (2024)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>There is debate about whether awareness during visual perception occurs abruptly (all-or-none) or gradually. One influential view is the
														levels of processing (LOP) theory which states that visual awareness depends on the stimulus. Low-level stimuli, such as color, evoke gradual
														awareness, while high-level stimuli, such as object identity, elicit abrupt, all-or-none perception. A critical source of evidence supporting
														LOP is that self-reported perceptual clarity measures reveal more intermediate values of perceptual clarity for low- (e.g. color) than high- 
														(e.g. letter) level stimuli. Here we provide several pieces of evidence inconsistent with this theory. First, previous studies confound stimulus
														level with category-flatness. Does increased perceptual clarity of X versus blue reflect that a noisy perception of X is perceived as X due to 
														large category priors for letter stimuli (e.g. there is no meaningful halfway point between X and M but there is between blue and red)? Consistent 
														with this, when we generated a high-level stimulus set that lacked meaningful category boundaries (by morphing unfamiliar faces into a continuous space)
														our results revealed gradual awareness. Second, by varying foil-target similarity, we show that an assumption underlying perceptual clarity measures—that
														they measure stimulus clarity not the difficulty of perceptual judgments—is incorrect. Finally, existing studies do not equate performance. This is 
														problematic because high-level stimuli have better performance, and the apparent all-or-none nature of categorical stimuli may reflect few intermediate 
														perceptual clarity ratings due to high confidence. Consistent with this, preliminary data suggests gradual awareness for all stimuli, including letters, 
														when task performance is equated across stimuli. Taken together, our findings reject the notion of separate awareness pathways for high- vs. low-level 
														stimuli and suggest that gradual versus all-or-none perception depends on other methodological properties.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix cpaper" data-year="2024">
													<div class="pubmain">
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Where’s Waldo in the mind: Accessing perceptual and semantic attributes in perception and working memory </h4>
                                                        <div class="pubauthor"> Sasin, E., Zhou, Y., <strong>Karabay, A.</strong>, Shrestha, S., & Fougnie, D.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>  The Vision Sciences Society Meeting (VSS2024) in Florida, USA. (2024)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>During perception, low-level features (such as color) are processed faster than high-level features (such as semantic properties). But what about
														accessing information from working memory? Recent work (Kong & Fougnie, 2021) has shown that search in working memory may be distinct from visual
														search regarding which features are most efficient. Further, research on long-term memory (Linde-Domingo, Treder, Kerrén, & Wimber, 2019) has 
														shown that semantic information is retrieved more rapidly than perceptual information. However, it is not yet known whether semantic properties
														are accessed faster from working memory than perceptual attributes. In two experiments, participants were shown four images that were either 
														animate or inanimate objects (semantic property) and which could be in the form of a photograph or drawing (perceptual property). Participants
														were pre-cued (perception – Experiment 1) or post-cued (working memory – Experiment 2) to the location of one of these objects. The cues were 
														accompanied by either a semantic (“animate or inanimate?”) or perceptual (“drawing or photograph?”) question. Unsurprisingly, perceptual aspects
														were discriminated faster than semantic aspects when the information was available to visual perception. However, when the task required accessing
														no longer presented information from working memory, participants took less time to respond to semantic than perceptual queries. These experiments,
														together with other recent findings, point to a reversal of the processing hierarchy for perception and memory. While visual perception is feed-forward,
														retrieving information in memory might first involve accessing high-level properties such as semantic categories, followed by access to lower-level visual properties.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix jpaper" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00173/120839/Concurrent-maintenance-of-both-veridical-and" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href=https://direct.mit.edu/imag/article-pdf/doi/10.1162/imag_a_00173/2373425/imag_a_00173.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/3hdpc" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
															
													    </div>
                                                        <h4 class="pubtitle">Concurrent maintenance of both veridical and transformed working memory representations within unique coding schemes</h4>
                                                        <div class="pubauthor">Kandemir, G., Wolff, M.J., <strong>Karabay, A.</strong>, Stokes, M.G., Axmacher, N., & Akyürek, E.G.</div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Imaging Neuroscience. (2024)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>In the dynamic environment we live in, the already limited information that human working memory can maintain needs to be constantly updated
														to optimally guide behaviour. Indeed, previous studies showed that leading up to a response, representations maintained in working memory 
														representations are transformed continuously. This goes hand-in-hand with the removal of task-irrelevant items. However, does such removal
														also include the representations of stimuli as they were originally, prior to transformation? Here we assessed the neural representation of 
														task-relevant transformed representations, and the no-longer-relevant veridical representations they originated from. We applied multivariate
														pattern analysis to electroencephalographic data during maintenance of orientation gratings with and without mental rotation. During maintenance,
														we perturbed the representational network by means of a visual impulse stimulus, and were thus able to successfully decode veridical as well as
														imaginary, transformed orientation gratings from impulse-driven activity. The impulse response reflected only task-relevant (cued), 
														but not task-irrelevant (uncued) items, suggesting that the latter were quickly discarded from working memory. By contrast, even though the
														original cued orientation gratings were also no longer task-relevant after mental rotation, these items continued to be represented next to
														the rotated ones, in different representational formats. This seemingly inefficient use of scarce working memory capacity was associated with
														reduced probe response times and may thus serve to increase precision and flexibility in guiding behaviour in dynamic environments.
														</p>
                                                    </div>
                                                </div>				
												
												
												
												<div class="item mix jpaper" data-year="2024">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S1053810023001642" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href="https://www.sciencedirect.com/science/article/pii/S1053810023001642/pdfft?md5=6013e46f651ec491aa01cdebbaed322b&pid=1-s2.0-S1053810023001642-main.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/am5y7/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
															
													    </div>
                                                        <h4 class="pubtitle">Attentional blur and blink: Effects of adaptive attentional scaling on visual awareness</h4>
                                                        <div class="pubauthor">Wang, S., <strong>Karabay, A.</strong>, & Akyürek, E.G.</div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Consciusness and Cognition. (2024)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Attentional scaling is a crucial mechanism that enables us to flexibly allocate our attention to larger or smaller regions in 
														the visual field. Although previous studies have demonstrated the critical role of attentional scaling in visual processing, its 
														impact on modulating visual awareness is not yet fully understood. This study investigates the adaptive control of attentional scaling 
														and its influence on visual awareness in an attentional blink paradigm. Participants were required to attend to the first target’s location, 
														which was manipulated either session-wise, trial-wise, or such that it could be learned across a block of trials. Discrete, all-or-none, 
														awareness was expected when attention was allocated to a narrow area, while gradual awareness was expected when attention was allocated 
														to a larger area. We used mixture modeling to assess second target awareness across these different attentional scales. The results revealed 
														that participants could adaptively control their attentional scale both across stable sessions, and through (implicit) statistical learning 
														in blocks of successive trials. This produced gradual perceptual awareness when the participants adopted a broad attentional scale, causing 
														an attentional “blur”. However, trial-wise cues did not allow for attentional scaling, resulting in more discrete target perception overall, 
														and an attentional “blink”. We conclude that the attentional scale is to some extent under adaptive control during the attentional blink/blur, 
														where it can produce qualitatively different modes of perceptual awareness.
														</p>
                                                    </div>
                                                </div>						
												
												
												<div class="item mix cpaper" data-year="2023">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Concealed familiar face detection with EEG in rapid serial visual presentation </h4>
                                                        <div class="pubauthor"> Chen, I., <strong>Karabay, A.</strong>, Mathȏt, S., Buchel, P., van der Mijn, R.,  Bowman, H., & Akyürek, E. G.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>  the 45th European Conference on Visual Perception (ECVP) in Paphos, Cyprus. (2023)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Classical concealed information tests (CITs) are in some circumstances able to detect concealed information, but are also vulnerable to countermeasures that participants can use to shield
															concealed information from detection. Rapid serial visual presentation (RSVP) has proven effective against such countermeasures, and can thus substantially reduce type-II error. Research to date has relied on classic univariate analyses of EEG
															data. Here we investigated whether RSVP-based CIT with multivariate analysis (decoding) of the EEG is potentially more effective for detecting ‘concealed knowledge’ of familiar faces. 29
															participants searched for a target face in an RSVP task while a familiar face (one of their parents’ faces), or one of two control
															faces also appeared in the stream. Using neural-network decoding, we detected concealed information for each individual
															with an average hit rate of 61.8% and an average correct rejection rate of 72.7%, while accuracy was 49.4% (around chance
															level), when we decoded one control face from the other. In comparison, univariate analyses were only able to detect familiar face recognition in 19 participants. Our findings suggest that 
															neural-network decoding makes RSVP-based CIT a more reliable method to detect concealed information.
														</p>
                                                    </div>
												</div>


												<div class="item mix cpaper" data-year="2023">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Introducing ART: a new method of testing auditory memory with circular reproduction tasks </h4>
                                                        <div class="pubauthor"> Fougnie, D., <strong>Karabay, A.</strong>, Nijenkamp, R., & Sarampalis, A.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>  The Vision Sciences Society Meeting (VSS2023) in Florida, USA. (2023)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Working memory research has largely focused on the visual domain, however, a full picture of working memory requires understanding its properties 
														in other domains (e.g., auditory). Recently, working memory tasks have focused on circular reproduction tasks, since these allow the separation of 
														putatively distinct mechanisms. Critically, such tasks have been leveraged only to study visual features (e.g., color & orientation) and have not been 
														expanded to the auditory domain. Here we developed a new methodology: Auditory reproduction task (ART). To overcome the challenge of creating a circular 
														space with auditory information, we relied on Shepard tones which create an illusion of infinite rising or falling tone frequency. We converted an octave 
														range of Shepard tones to a 0-360° circular space. In the first experiment, we validated the perceptual circularity of the Shepard tones with multidimensional 
														scaling. The perceptual space of the tones resembled an almost perfect circle. In the second experiment, we demonstrated that auditory working memory shows 
														set-size effects, similar to visual working memory. Specifically, reproduction errors increased when participants were required to retain two (sequentially 
														presented) versus one tone. Further, the preliminary results, when subjected to mixture modeling, revealed that precision decreased as a function of set size, 
														demonstrating that the theoretical models on visual working memory can be used to study auditory working memory. Similar to visual working memory, we found 
														evidence that the non-tested item influenced responses to the tested item—repulsion when the distance between the two random tones was small and attraction 
														when the distance was large. Taken as a whole, these findings validate the ART task as a useful tool to study the properties of auditory working memory and 
														how they may be similar to (or differ from) visual working memory.
														</p>
                                                    </div>
												</div>
												
												
												<div class="item mix cpaper" data-year="2023">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Concealed familiar face detection with oculomotor measures and EEG in rapid serial visual presentation </h4>
                                                        <div class="pubauthor"> Chen, I., Mathȏt, S., van der Mijn, R., <strong>Karabay, A.</strong>, Bowman, H., & Akyürek, E. G.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>  The Vision Sciences Society Meeting (VSS2023) in Florida, USA. (2023)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Traditional concealed information tests (CIT) work fairly well, but people can still use countermeasures to avoid detection. Presenting 
														the critical stimuli in rapid serial visual presentation (RSVP) while measuring EEG has proven effective against countermeasures. We investigated
														here to what extent concealed information (familiar faces) are also detectable in RSVP-based CIT with oculomotor measures, in particular pupil 
														size and micro-saccades. In our two studies (one with oculomotor measures and one with EEG), 31 and 34 participants, respectively, were asked to
														search for a target face in an RSVP task, while a familiar face, one of their parents’ faces, or a control face also appeared in the task. We 
														found that the pupil dilated more in response to the familiar faces, as compared to control faces, an effect that was most pronounced when looking 
														at the velocity of pupil-size changes, rather than pupil size itself. Micro-saccades did not seem to add much information. Overall, EEG remained 
														more sensitive than the oculomotor measures, but concealed information detection by means of the latter was nevertheless substantial. Taking 
														practical considerations into account, the application of oculomotor measures in RSVP-based CIT may thus present a viable alternative to EEG.
														</p>
                                                    </div>
												</div>


												<div class="item mix cpaper" data-year="2023">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Attentional blur and blink: Effects of adaptive attentional scaling on visual awareness </h4>
                                                        <div class="pubauthor">Wang, S., <strong>Karabay, A.</strong>, & Akyürek, E. G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span> 23st Conference of the European Society for Cognitive Psychology (ESCoP) in Porto, Portugal. (2023)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Attentional scaling is a mechanism allowing us to allocate our attention flexibly to larger or smaller regions, the role of which in visual processing has been established 
														in previous studies. However, little is known about its role in modulating visual awareness. This study investigated how attentional scaling can be adaptively controlled and 
														influence visual awareness. We employed an attentional blink (AB) paradigm that highlights the temporal limits of attentional selection. The first target’s location was either 
														explicitly cued, block-wise or trial-wise, or implicitly learned. Narrow attentional scaling resulted in discrete awareness, whereas broader one produced gradual awareness.
														Mixture modeling was used to assess second target awareness across attentional scaling conditions. We found that participants were able to adjust attentional scaling through
														both explicit block-wise cues and implicit learning, leading to a gradual awareness (attentional blur). Trialwise cues did not allow attentional scaling, causing more discrete
														target perception overall (attentional blink). Our study thus showed that attentional scaling could be adaptively controlled during the AB, leading to qualitatively different 
														perceptual awareness.
														</p>
                                                    </div>
												</div>												
												
												<div class="item mix cpaper" data-year="2023">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Concealed familiar face detection with EEG in rapid serial visual presentation </h4>
                                                        <div class="pubauthor">Chen, I., Mathȏt, S., van der Mijn, R., <strong>Karabay, A.</strong>, Bowman, H., & Akyürek, E. G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span> 23st Conference of the European Society for Cognitive Psychology (ESCoP) in Porto, Portugal. (2023)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Classical concealed information tests (CITs) are in some circumstances able to detect concealed information, but vulnerable to countermeasures 
														that participants can use to shield concealed information from detection. Rapid serial visual presentation (RSVP) has proven effective against such
														countermeasures, and can thus substantially reduce type-II error. Research to date has relied on classic univariate analyses of EEG data. Here we
														investigated whether RSVP-based CIT with multivariate analysis (decoding) of the EEG is potentially more effective for detecting 'concealed knowledge'
														of familiar face. 29 participants searched for a target face in an RSVP task while a familiar face (one of their parents' faces), or one of two control
														faces also appeared. Using neural network decoding, we detected concealed information for each individual with an average hit rate of 61.8% and an average 
														correct rejection rate of 72.7%, while accuracy was around chance level when we decoded one control face from the other. In comparison, univariate analyses
														were only able to detect familiar face recognition in 19 participants. Our findings suggest that neural network decoding makes RSVP-based CIT a more reliable
														method to detect concealed information.
														</p>
                                                    </div>
												</div>
												
												
												<div class="item mix jpaper" data-year="2023">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://journals.sagepub.com/doi/10.1177/02698811231161579" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href="https://journals.sagepub.com/doi/pdf/10.1177/02698811231161579?download=true" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/tqyme/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">The effects of gamma-aminobutyric acid (GABA) on working memory and attention: A randomised, double-blind, placebo-controlled, crossover trial</h4>
                                                        <div class="pubauthor">Altınok, A., <strong>Karabay, A.</strong>, de Jonge, J., Balta, G., & Akyürek, E. G.</div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Journal of Psychopharmacology. (2023)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p><strong>Background:</strong> γ-aminobutyric acid (GABA) is a primary inhibitory neurotransmitter that plays a
														significant role in the central nervous system. Studies on both animals and humans show it has
														the pharmacological potential for reducing the impact of cognitive disorders, as well as enhancing
														cognitive functions and mood. However, its specific effects on human attention and working
														memory have not yet been extensively studied.</p>
														<p><strong>Aims:</strong> In this randomised, double-blind, placebo-controlled, and crossover trial, we aimed to test
														whether the administration of 800 mg GABA, dissolved in a drink, acutely affected visual working
														memory maintenance, as well as temporal and spatial attention in healthy adults.
														Methods: The participants were 32 young adults (16 females and 16 males). Working memory
														recall precision, spatial attention and temporal attention were measured by a delayed match-tosample task, a visual search task, 
														and a speeded rapid serial visual presentation task,
														respectively. Participants completed two experimental sessions (GABA and Placebo) in
														randomized and counterbalanced order. In each session, forty-five minutes after administration
														of the drink, they completed the all three of the aforementioned cognitive tasks.</p>
														<p><strong>Results:</strong> Linear mixed model analysis results showed that GABA increased visual search time,
														compared to the placebo, but did not affect visual search accuracy, temporal attention, nor visual
														working memory precision.</p>
														<p><strong>Conclusions:</strong> The results suggest that GABA increases visual search time but does not affect
														temporal attention and memory, and that previously reported effects on cognition might rely on
														other functions.
														</p>
                                                    </div>
                                                </div>						





												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Probing latent working memory representations in EEG </h4>
                                                        <div class="pubauthor">Akyürek, E. G., Kandemir, G., Wolff, M., <strong>Karabay, A.</strong> , & Wilhelm, S.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span> 22st Conference of the European Society for Cognitive Psychology (ESCoP) in Lille, France. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Working memory (WM) allows us to hold onto information for a brief, but critical interval, 
														thereby providing the backbone of intelligent, adaptive behavior. WM seems to rely not only on 
														ongoing neural activity, but also on connectivity, which is activity-quiescent or even 
														activity-silent. Measuring such latent states is challenging, since they are effectively 
														invisible to standard measures in cognitive neuroscience. However, by presenting a visual
														impulse to perturb the underlying brain network, in combination with multivariate pattern 
														analysis of the resultant impulse response signal, it is possible to illuminate and reveal
														representations held in quiescent network states. In a series of EEG experiments based on the
														perturbation technique, we found pervasive evidence for continued maintenance of seemingly
														useless information; from previously transformed items, to de-prioritized items, and 
														task-irrelevant properties. It thus seems that WM may hold more than meets the eye, particularly
														with regard to functionally and physiologically latent items.</p>
                                                    </div>
												</div>												
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> The Acute Effects of Caffeine and Cocoa Flavanols on Working Memory and Attention </h4>
                                                        <div class="pubauthor"> Altınok, A., <strong>Karabay, A.</strong>, Lorist, M. M., Weiden, D., & Akyürek, E.G.  </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span> 22st Conference of the European Society for Cognitive Psychology (ESCoP) in Lille, France. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>This study tests the acute synergistic effects of caffeine and cocoa flavanols (CF) consumption on working memory, spatial attention,
														and temporal attention in healthy adults with a randomized, double-blinded, placebo-controlled, counterbalanced, crossover, 
														and pre-registered design. While CF consumption facilitates attention due to vasodilation, caffeine improves information processing speed. 
														However, little is known about the synergetic effects of CF and caffeine on cognition. We will employ a free-recall task for working memory
														precision, a visual search task for spatial attention, and speeded rapid serial visual presentation task for temporal attention. In the 
														synergy condition, 200 mg caffeine and 415 mg CF will be administered prior to the test session, and subsequent task performance will be
														compared to a placebo condition. We expect caffeine and CF consumption to increase working memory precision and the accuracy of temporal 
														and spatial attention and potentially decrease reaction times in temporal and spatial attention tasks.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Concealed familiar face detection with pupillometry in rapid serial visual presentation </h4>
                                                        <div class="pubauthor">Chen, I., Buchel, P.,<strong>Karabay, A.</strong>, Mathȏt, S., & Akyürek, E. G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span> 22st Conference of the European Society for Cognitive Psychology (ESCoP) in Lille, France. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Traditional concealed information tests (CIT) work fairly well, but people can still use countermeasures
														to avoid detection. Presenting the critical stimuli in rapid serial visual presentation (RSVP) while measuring
														EEG has proven effective against countermeasures. We investigated here whether pupil size is also an effective 
														measure in RSVP-based CIT. In our study, 31 participants were asked to search for a target face in an RSVP task
														while a familiar face, one of their parents' faces, and a control face also appeared in the task. We found that
														the pupil dilated more in response to the familiar faces, as compared to control faces. We also found that 7
														participants showed this effect when analysed individually. Our results show that an RSVP-based CIT with
														pupillometry can detect concealed familiar faces at a group level. Further development of the method may produce
														a valid and reliable concealed information detector at the individual level.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle"> Pinging attentional task rules: Neural mechanisms underlying attending and suppressing in visual search tasks </h4>
                                                        <div class="pubauthor"> <strong>Karabay, A.</strong>, Kandemir, G., Kovács, E.R., & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span> 22st Conference of the European Society for Cognitive Psychology (ESCoP) in Lille, France. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Is attention a one-way street, or can we suppress stimuli the same as we attend to them? In a visual search task during
														which the direction of a target's tilt was reported, the nature of color cues was manipulated. Participants were informed
														that a color precue identified either the placeholder color of the target (attend), of a distractor (suppress), or neither
														of them (baseline). To measure latent EEG states, a visual impulse was inserted between the precue and visual search. 
														Analysis of reaction times showed a benefit in the attend condition compared to the suppress and baseline conditions.
														No benefit of the suppress condition over the baseline was observed. Drift diffusion models confirmed that the benefits
														in the attend condition were due to quicker non-decision time, indicating that attentional selection was faster. The EEG 
														patterns of colors will be contrasted to determine the task rule and infer underlying neural mechanisms.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Which working memory model accounts best for target representation during the attentional blink? </h4>
                                                        <div class="pubauthor">Wang, S, <strong>Karabay, A.</strong>, & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span> 22st Conference of the European Society for Cognitive Psychology (ESCoP) in Lille, France. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The attentional blink (AB) is a phenomenon in which identification of the second target is limited when it is presented
														shortly after the first one. One of the working memory (WM) models, the standard mixture model, has been widely used to
														investigate why such limitations arise. However, no existing study has systematically compared WM models in the AB domain.
														We compared eight commonly used visual WM models during the AB deficiency with data sets of three independent laboratories.
														Specifically, we utilized a maximum likelihood estimation to analyze these models and assessed them with the Bayesian 
														information criterion. Results suggest that the standard mixture model, slot model, and variants have better fitness to 
														most data sets than the swap, ensemble integration and variable precision models. Furthermore, stimuli characteristics 
														(e.g., colors or orientations) and their spatial arrangement in the AB task lead to different model rankings.
														</p>
                                                    </div>
												</div>
												
												<div class="item mix jpaper" data-year="2023">
                                                    <div class="pubmain">
													
														<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://onlinelibrary.wiley.com/doi/10.1111/psyp.14155" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
                                                            <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/psyp.14155" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/9fkpm/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">Concealed identity information detection with pupillometry in rapid serial visual presentation</h4>
                                                        <div class="pubauthor">Chen, I. Y., <strong>Karabay, A.</strong> Mathot, S., Bowman, H., & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Psychophysiology. (2023)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The concealed information test (CIT) relies on bodily reactions to stimuli that are hidden in mind. However, people can use countermeasures,
														such as purposely focusing on irrelevant things, to confound the CIT. A new method designed to prevent countermeasures uses rapid serial visual
														presentation (RSVP) to present stimuli on the fringe of awareness. Previous studies that used RSVP in combination with electroencephalography (EEG)
														showed that participants exhibit a clear reaction to their real first name, even when they try to prevent such a reaction (i.e. when their name is
														concealed information). Since EEG is not easily applicable outside the laboratory, we investigated here whether pupil size, which is easier to measure,
														can also be used to detect concealed identity information. In our first study, participants adopted a fake name, and searched for this name in an RSVP
														task, while their pupil sizes were recorded. Apart from this fake name, their real name and a control name also appeared in the task. We found pupil 
														dilation in response to the task-irrelevant real name, as compared to control names. However, while most participants showed this effect qualitatively,
														it was not statistically significant for most participants individually. In a second study, we preregistered the proof-of-concept methodology and 
														replicated the original findings. Taken together, our results show that the current RSVP task with pupillometry can detect concealed identity information
														at a group level. Further development of the method is needed to create a valid and reliable concealed identity information detector at the individual level.</p>
                                                    </div>
                                                </div>
											
												<div class="item mix jpaper" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://www.psikolog.org.tr/tr/yayinlar/dergiler/1031828/tpy1301996120211203m000043.pdf" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
													    </div>
                                                        <h4 class="pubtitle">Uzun Süreli Kakao Flavanolleri Alımının Bilişsel İşlevlere ve Duygudurumuna Etkileri ve Bu Etkilerin Altındaki Fizyolojik Mekanizmalar: Bir Derleme Çalışması</h4>
                                                        <div class="pubauthor">Karataş, O., <strong>Karabay, A.</strong>, & Alıcı, T.</div>
                                                        <div class="pubcite"><span class="label label-success">Review Paper</span> Turk Psikoloji Yazilari. (2022)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Öz</h4>
                                                        <p>Son yıllarda flavanol bakımından zengin kakao ve kakao ürünlerinin sinir sistemi dahil olmak üzere sağlığa faydaları
														net bir şekilde gösterilmiştir. Bu inceleme yazısının amacı uzun süreli kakao flavanolleri alımının yönetici işlevler,
														dikkat ve bellek gibi çeşitli bilişsel işlevler ve duygudurum üzerindeki etkilerini inceleyen seçkisiz kontrollü çalışmaları 
														özetlemek ve bu etkilerin altında yatan fizyolojik mekanizmayı tartışmaktır. İnsan ve deney hayvanlarıyla yapılan in vivo ve in
														vitro çalışmalar, kakao flavanollerinin bilişsel işlevler ve duygudurumuna olan olumlu katkısının, kan damarlarını genişletme,
														nörotransmitter görevi görme ve insülin duyarlılığını artırma gibi çeşitli işlevlere sahip nitrik oksitin biyoyararlanımını 
														artırarak gerçekleştiğini göstermektedir. Ayrıca, yüksek antioksidan kapasitesine ve nöral koruma özelliklerine sahip kakao 
														flavanollerinin reseptörler, enzimler ve sinyal yolakları üzerinde doğrudan etkileri aracılığıyla, bilişsel olarak sağlıklı
														bireylerde bilişsel işlevleri destekleyeceği, yaşlanmayla birlikte kaçınılmaz olarak ortaya çıkan bilişsel gerilemeyi önleyeceğine 
														dair güçlü kanıtlar sunulmuştur. Kakao flavanolleri çalışmalarında gözlemlenen farklı bulgulara rağmen, doza ve uygulama süresine
														bağlı olarak, uzun süreli kakao flavanolleri alımı duygudurumu düzenlemekte; dikkat, işlemleme hızı ve çalışma belleği gibi 
														çeşitli bilişsel işlevleri desteklemektedir.</p>
                                                    </div>
                                                </div>
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">A visual impulse reveals memoranda embedded in functional connectivity: Evidence for activity-silent WM states </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong> & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>International Conference of Cognitive Neuroscience 2020 in Helsinki, Finland. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>A task-irrelevant, high-contrast stimulus can be used as a visual impulse signal to implement a functional
														non-invasive perturbation method that reveals working memory (WM) content. Stokes (2015) suggested
														that the impulse acts like a sonar signal used in echolocation, from which structural information (e.g., the
														surface of the ocean floor) can be derived. Similarly, in the brain the visual impulse reveals memoranda
														embedded in functional connectivity, which might by themselves be activity-silent. However, Barbosa et al.
														(2021) suggested that the impulse might only decrease non-WM-related EEG noise, thereby improving the
														ability to decode already-active memoranda. In this study, we sought to arbitrate between these two
														possibilities. We matched a task-irrelevant feature (spatial frequency) of a visual impulse with memory
														items (orientation gratings), while equalizing intensity and contrast. Better decoding of WM content in the
														match condition than in the no-match condition would suggest that the impulse interacts with the actual
														content within WM network, in line with activity-silent accounts. Conversely, if no differences between
														conditions are observed, this would fit with a noise reduction account, and suggest that WM might rely
														primarily on active storage. Results showed an advantage for matching impulses, supporting the former
														hypothesis that visual impulses work as a neural sonar. Further, although the visual impulse decreased
														average EEG variance, there was no difference between match and no-match conditions. We conclude that
														visual impulse perturbation reveals memoranda embedded in functional connectivity, in line with the idea
														that WM might rely on activity-silent states.</p>
                                                    </div>
												</div>	
											
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Concealed information detection with pupillometry in rapid serial visual presentation </h4>
                                                        <div class="pubauthor">Chen, I. Y., Buchel, P. <strong>Karabay, A.</strong> Mathot, S., Bowman, H., & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>International Conference of Cognitive Neuroscience 2020 in Helsinki, Finland. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The concealed information test (CIT) relies on bodily reactions to stimuli that are hidden in mind.
														However, people can use countermeasures, such as purposely focusing on irrelevant things, to confound
														the CIT. A method designed to prevent the use of countermeasures, based on rapid serial visual
														presentation (RSVP), presents each stimulus on the fringe of awareness. Previous studies showed that this
														RSVP in combination with electroencephalography (EEG) is valid at detecting information with various levels
														of salience, even when participants try to prevent such a reaction. Since EEG measures are not easily
														applicable outside the laboratory, we investigated here whether pupil size, which is easier to measure, is
														also a valid measure with this RSVP-based CIT. In our first study, 31 participants were asked to adopt a fake
														name, and search for this name in an RSVP task, while their pupil sizes were recorded. Apart from this fake
														name, their real name and a control name also appeared in the task. We found that the pupil dilated more
														in response to the task-irrelevant real name, as compared to control names. However, while most
														participants showed this effect qualitatively, it was only statistically significant for 6 participants when
														analysed individually. As a second study, we preregistered the proof-of-concept methodology and
														replicated the findings of the first one. In our third study, 31 participants were asked to search for a target
														face in an RSVP task while one of their parents’ faces and a control face also appeared in the task. We found
														that the pupil dilated more in response to their parents’ face, as compared to control faces. We also found
														that 7 participants showed this effect when analysed individually. Taken together, our results show that the
														current RSVP task with pupillometry can detect concealed information of identity and parents’ faces at a
														group level. Further development of the method may produce a valid and reliable concealed information
														detector at the individual level.
														</p>
                                                    </div>
												</div>	
												
												
												<div class="item mix book" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://www.egitenkitap.com/fizyolojik-psikoloji?search=fizyolojik%20psikoloji" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            
                                                        </div>

                                                        <h4 class="pubtitle">
                                                            Duyum ve Algı
                                                        </h4>
                                                        <div class="pubauthor"> <strong>Karabay, A.</strong></div>
                                                        <div class="pubcite">
                                                            <span class="label label-primary">Kitap Bölümü</span>Fizyolojik Psikoloji. (2022)
                                                        </div>
                                                        
                                                    </div>
                                                </div>
												
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Visual impulse perturbation: Neural sonar or just noise-reducer? </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong> Wolff, M.J., Ruuskanen, V., & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>18th NVP Winter Conference in Egmond, Netherlands. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>A task-irrelevant, high contrast stimulus can be used as a visual impulse signal to implement a functional non-invasive 
														perturbation method that can reveal working memory (WM) content. Stokes (2015) suggested that the impulse acts like a sonar 
														signal used in echolocation, from which structural information (e.g., the surface of the ocean floor) can be derived. Similarly,
														in the brain the visual impulse reveals memoranda embedded in functional connectivity, which are by themselves activity-silent. 
														However, Barbosa et al. (2021) suggested that the impulse might only decrease non-WM-related EEG noise, thereby improving the
														ability to decode already-active memoranda. In this study, we sought to arbitrate between these two possibilities. We matched 
														a task-irrelevant feature (spatial frequency) of a visual impulse with the memory items (orientation gratings), while equalizing
														intensity and contrast. Better decoding of WM content in the match condition than in the no-match condition would suggest that 
														the impulse interacts with the actual content within WM network, in line with activity-silent accounts. Conversely, if no differences
														between conditions are observed, this would fit with a noise reduction account, and suggest that WM might rely primarily on active
														storage. Preliminary results showed an advantage for matching impulses, supporting the former hypothesis.
														</p>
                                                    </div>
												</div>	
												
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Which working memory model accounts best for target representation in the attentional blink?</h4>
                                                        <div class="pubauthor">Wang, S, <strong>Karabay, A.</strong>, & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>18th NVP Winter Conference in Egmond, Netherlands. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>People often fail to detect the second of two briefly presented target stimuli when the time interval between them is within 200-500 msec.
														This phenomenon is known as the attentional blink (AB). The current literature suggests that the standard mixture model of working memory (WM)
														explains representation during the AB better than resource-based models. However, no existing study has systematically compared WM models in 
														the AB domain. Here, we compare eight models commonly used in visual WM studies. Firstly, we fitted each model to the data collected from 3 
														separate laboratories. Next, the Bayesian information criterion (BIC) values were calculated for each model at an individual level, across 
														different conditions and experiments. Finally, the average model rankings were obtained based on the BIC values. Our findings indicated that,
														for most experiments presented here, the standard mixture model, the slot model, and their variants perform best in accounting for the data. 
														Meanwhile, the results also showed that the kind of stimuli (e.g., colors or orientations) and/or their spatial arrangement in the AB task can
														lead to markedly different model rankings. Our study demonstrates the applicability of WM models and allows for a principled selection of models
														in the AB field.
														</p>
                                                    </div>
												</div>	
												
												
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Concealed identity information detection with pupillometry in rapid serial visual presentation</h4>
                                                        <div class="pubauthor">Chen, I. Y., <strong>Karabay, A.</strong> Mathot, S., Bowman, H., & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>18th NVP Winter Conference in Egmond, Netherlands. (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>The traditional concealed information test (CIT) can be confounded by countermeasures. Previous studies showed a new CIT method,
														based on rapid serial visual presentation (RSVP), in combination with electroencephalography (EEG), is able to prevent the use of 
														countermeasures when detecting concealed identity information (participants' real name). Since EEG measures are not easily applicable
														outside the laboratory, we investigated here whether pupil size, which is easier to measure, is also able to detect concealed identity
														information. In our study, 31 participants were asked to adopt a fake name, and search for this name in an RSVP task, while their pupil
														sizes were recorded. Apart from this fake name, their real name and a control name also appeared in the task. We found that the pupil
														dilated more in response to the task-irrelevant real name, as compared to control names. However, while most participants showed this
														effect qualitatively, it was not statistically significant for most participants when analysed individually. Taken together, our results
														show that the current RSVP task with pupillometry can detect concealed identity information at a group level. Further development of the
														method is needed to create a valid and reliable concealed identity information detector at the individual level.
														</p>
                                                    </div>
												</div>	
												
														
												<div class="item mix cpaper" data-year="2022">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">The effects of gamma-aminobutyric acid (GABA) on working memory and attention</h4>
                                                        <div class="pubauthor">Altınok, A., Balta, G., <strong>Karabay, A.</strong>, & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>18th NVP Winter Conference in Egmond, Netherlands, (2022)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Our study aims to test the acute effects of GABA consumption on visual working memory, spatial attention and temporal attention in
														healthy adult volunteers. GABA acts as a neurotransmitter in the brain, and is also commonly found in various foods such as tomato, 
														sweet potato, spinach and soy beans. We hypothesize that GABA consumption might acutely affect cognitive processes. To test this idea,
														we set up a randomized, double-blinded, placebo-controlled, counterbalanced, and crossover experiment, with 32 young adults (aged 18-25)
														taking part. In the experiment, working memory recall precision will be measured in a task that requires the maintenance of grating 
														orientations in memory. Spatial attention will be measured with a visual search task, and a speeded rapid serial visual presentation 
														task will be used to measure temporal attention. In the critical condition, 800 mg GABA will be administered prior to the test session, 
														and subsequent task performance will be compared to a placebo condition. Participants’ body mass index and gender will also be considered
														in the analysis. We expect GABA consumption to increase working memory precision, as well as the accuracy of temporal and spatial attention,
														and potentially decrease reaction times in temporal and spatial attention tasks as well.
														</p>
                                                    </div>
												</div>	
											
												<div class="item mix jpaper" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/article/10.1007/s00394-021-02767-x" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
															<a href="https://link.springer.com/content/pdf/10.1007/s00394-021-02767-x.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
													    </div>
                                                        <h4 class="pubtitle">Acute effects of cocoa flavanols on visual working memory: Maintenance and updating</h4>
                                                        <div class="pubauthor">Altinok, A., <strong>Karabay, A.</strong>, & Akyürek, E. G.  </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> European Journal of Nutrition. (2022)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p><strong>Background:</strong> Consumption of cocoa flavanols may have acute physiological effects on the brain due to their ability to activate nitric oxide synthesis. Nitric oxide mediates vasodilation, which increases cerebral blood flow, and can also act as a neurotransmitter.</p> 
														<p><strong>Objectives:</strong> This study aimed to examine whether cocoa flavanols have an acute influence on visual working memory (WM).</p> 
														<p><strong>Methods:</strong> Two randomised, double-blind, baseline- and placebo-controlled, counterbalanced crossover experiments were conducted on normal healthy young adult volunteers (NExp1=48 and NExp2=32, gender-balanced). In these experiments, 415 mg cocoa flavanols have been administered to show its acute effects on visual working memory. In the first experiment, memory recall precision was measured in a task that required only passive maintenance of grating orientations in WM. In the second experiment, recall was measured after active updating (mental rotation) of WM contents. Habitual daily flavanols intake, body mass index, and gender were also considered in the analysis.</p>
														<p><strong>Results:</strong> The results suggested that neither passive maintenance in visual WM nor active updating of WM was acutely enhanced by consumption of cocoa flavanols. Exploratory analyses with covariates (body mass index and daily flavanols intake), and the between-factor of gender also showed no evidence for effects of cocoa flavanols, neither in terms of reaction time, nor accuracy.</p>
														<p><strong>Conclusions:</strong> Overall, cocoa flavanols did not improve visual working memory recall performance during maintenance, nor did it improve recall accuracy after memory updating.</p>
                                                    </div>
                                                </div>
												
												
												<div class="item mix jpaper" data-year="2022">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://psycnet.apa.org/record/2022-05374-001" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
                                                            <a href="/Files/articles/Karabayetal2022JEPG.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/x5dru/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">Two faces of perceptual awareness during the attentional blink: Gradual and discrete</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>, Wilhelm, S. A., de Jonge, J., Wang, J., Martens, S., & Akyürek, E. G.  </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Journal of Experimental Psychology: General. (2022)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>In a series of experiments, the nature of perceptual awareness during the attentional blink was investigated. Previous 
														work has considered the attentional blink as a discrete, all-or-none phenomenon, indicative of general access to conscious
														awareness. Using continuous report measures in combination with mixture modeling, the outcomes showed that perceptual awareness
														during the attentional blink can be a gradual phenomenon. Awareness was not exclusively discrete, but also exhibited a gradual 
														characteristic whenever the spatial extent of attention induced by the first target spanned more than a single location. Under
														these circumstances, mental representations of blinked targets were impoverished, but did approach the actual identities of the 
														targets. Conversely, when the focus of attention covered only a single location, there was no evidence for any partial knowledge 
														of blinked targets. These two different faces of awareness during the attentional blink challenge current theories of both 
														awareness and temporal attention, which cannot explain the existence of gradual awareness of targets during the attentional blink.
														To account for the current outcomes, an adaptive gating model is proposed that casts awareness on a continuum between gradual and
														discrete, rather than as being of either single kind.</p>
                                                    </div>
                                                </div>
																								
												<!--Book Chapter-->
												<div class="item mix book" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://pegem.net/urun/Herkes-Icin-Istatistiksel-Programlama-ve-Analiz/61909" class="tooltips" title="link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            
                                                        </div>

                                                        <h4 class="pubtitle">
                                                            Herkes icin istatistiksel programlama ve analiz (Introduction to R)
                                                        </h4>
                                                        <div class="pubauthor">Richard Cotton, <i>translated to Turkish by</i> Sünbül, Ö., Sünbül, S.Ö., & <strong>Karabay, A.</strong></div>
                                                        <div class="pubcite">
                                                            <span class="label label-primary">Book translation</span> Pegem Academy Press, İstanbul, Turkey. (2020)
                                                        </div>
                                                        
                                                    </div>
                                                    <div class="pubdetails">
                                                        <img alt="image" src="img/pubs/Rbook.png" align="left"  style="padding:0 30px 30px 0;">
                                                        <h4>Herkes icin istatistiksel programlama ve analiz</h4>
														<p>R istatistiksel programlama ve analiz için geliştirilmiş olan güçlü bir programlama dilidir. Yurtdışında yaygın olarak kullanılmakta ve birçok üniversitede lisansüstü ders olarak okutulmaktadır.  Bu programlama dili açık kaynak kodlu olduğundan dolayı programa rahatlıkla ulaşılabilmektedir ve program ücretsiz olarak kullanılabilmektedir. R istatistiksel analize ihtiyaç duyulan hemen hemen bütün bilim alanlarında (sosyal, sağlık, fen, ekonomi vb.) kullanılabilmektedir. R, çok geniş bir kütüphaneye sahiptir ve bu kütüphane gün geçtikçe artan bir ivmeyle gelişmeye devam etmektedir. R'ın yakın bir gelecekte popüler istatistiksel programların yerini alacağı düşünülmektedir. Kitabın içeriği basitten karmaşığa doğru olacak şekilde adım adım  kurgulanmıştır. Herhangi bir programlama dili deneyimine sahip olmayan bireylerin dahi rahatlıkla istatistiksel programlama ve analiz yapmasına olanak sağlamaktadır.</p>
                                                    </div>
                                                </div>
												
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://www.journalofcognition.org/articles/10.5334/joc.127/" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i> 
                                                            </a>
                                                            <a href="https://www.journalofcognition.org/articles/10.5334/joc.127/galley/358/download/" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">Discriminating global orientation of two element Sets</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong> &  Kurylo, D. D. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Journal of Cognition. (2020)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Perceived global organization of visual patterns is based upon the aggregate contribution of constituent components. 
														Patterns constructed from multiple sources cooperate or compete for global organization. An investigation was made here 
														of interactions between two interspersed element sets on global orientation. It was hypothesized that each set would operate 
														as an integrated unit, and contribute independently to global orientation. Participants viewed a 10 x 10 array of Gabor patches,
														and indicated the predominant orientation of the array. In Experiment 1 8 all elements were rotated. Rotation up to 23° had little effect,
														whereas greater rotation produced a progressive shift on global orientation. In Experiment 2 a proportion of elements remained aligned
														while remaining elements were rotated. Embedding a proportion of aligned elements stabilized global orientation, which was dependent 
														upon the proportion of aligned elements. Specifically, with 20% alignment, global orientation was similar to rotating all elements,
														whereas 80% alignment strongly biased perception towards aligned elements. The stabilizing effect varied with rotation of the second 
														element set. Across levels of rotation, alignment effects rose to a peak then declined as element sets became orthogonal. 
														In Experiment 3, each element set was rotated independently. Independent rotation of both sets altered global orientation, 
														compressing the psychometric function for the single-element condition. Together, for interspersed element sets with explicit orientations,
														each set does not contribute independently to global orientation. Instead, element sets interact, where the contribution of one set, 
														presented at a fixed rotation and fixed proportion, varies with the change to the second set.</p>
                                                    </div>
                                                </div>
												
											<!--Books in the format below-->
												<div class="item mix book" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
															<a href="/Files/articles/FromStimulustoRepresentation_PhDthesis_book.pdf" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
                                                            
                                                        </div>

                                                        <h4 class="pubtitle">
                                                            From stimulus to tepresentation: Target identification in rapid serial visual presentation
                                                        </h4>
                                                        <div class="pubauthor"> <strong>Karabay, A.</strong></div>
                                                        <div class="pubcite">
                                                            <span class="label label-primary">PhD thesis</span> (2020)
                                                        </div>
                                                        
                                                    </div>
                                                    <div class="pubdetails">
                                                        <img alt="image" src="img/pubs/PhDthesis.png" align="left"  style="padding:0 30px 30px 0;">
                                                        <h4>From stimulus to tepresentation: Target identification in rapid serial visual presentation</h4>
														<p>This dissertation investigated the relationship between target identification and temporal integration with three studies. Rapid serial visual presentation tasks were used to investigate empirical questions, where two targets are embedded in a set of distracters, and the task is to identify targets. Temporal integration is a phenomenon that temporally separated targets fall into the same perceptual episode. The first study investigated whether a change in low-level stimulus features (color/contrast) influences temporal attention and integration. The results showed that a categorical change of target color decreases the competition between targets resulting in better target identification and more frequent integrations. Besides, the study confirmed the literature that high contrast stimuli mask low contrast stimuli if their temporal proximity is close. The second study investigated if Gestalt properties influence the temporal binding of targets and target identification. In addition to studies that show parts of objects are grouped in space, the second study showed that if temporally separated targets form a figure, their integrated percepts and identifications are facilitated. Lastly, how a change in mental state with consumption of cocoa flavanols, which increases blood flow in brain arteries, influences target identification and integrations were investigated. There was no effect of cocoa flavanols on temporal attention and integration. In addition, the study showed that cocoa flavanols improve the efficiency of visual search. In sum, target identification and integration are both influenced by exogenous stimuli properties and by flavanol-induced changes in mental state, and often also in a similar direction.</p>
                                                    </div>
                                                </div>
												
											
											<!--Articles in the format below-->
												<div class="item mix jpaper" data-year="2019">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://www.sciencedirect.com/science/article/pii/S0001691818305043" class="tooltips" title="External link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="https://psyarxiv.com/ehzuj/download" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="https://osf.io/rwkx8/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">Temporal integration and attentional selection of color and contrast target pairs in rapid serial visual presentation</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong> &  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Acta Psychologica. (2019)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Performance in a dual target rapid serial visual presentation task was investigated, dependent on whether the
														color or the contrast of the targets was the same or different. Both identification accuracy on the second target,
														as a measure of temporal attention, and the frequency of temporal integration were measured. When targets had
														a different color (red or blue), overall identification accuracy of the second target and identification accuracy of
														the second target at Lag 1 were both higher than when targets had the same color. At the same time, increased
														temporal integration of the targets at Lag 1 was observed in the different color condition, even though actual
														(non-integrated) single targets never consisted of multiple colors. When the color pairs were made more similar,
														so that they all fell within the range of a single nominal hue (blue), these effects were not observed. Different
														findings were obtained when contrast was manipulated. Identification accuracy of the second target was higher
														in the same contrast condition than in the different contrast condition. Higher identification accuracy of both
														targets was furthermore observed when they were presented with high contrast, while target contrast did not
														influence temporal integration at all. Temporal attention and integration were thus influenced differently by target
														contrast pairing than by (categorical) color pairing. Categorically different color pairs, or more generally,
														categorical feature pairs, may thus afford a reduction in temporal competition between successive targets that
														eventually enhances attention and integration.</p>
                                                    </div>
                                                </div>
												<!--Conference contributions in the format below-->
												<div class="item mix cpaper" data-year="2019">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
														<h4 class="pubtitle">The Attentional Blink: Binary Or Gradual?</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>, Wang, J., Martens, S., & Akyürek, E. G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>21st Conference of the European Society for Cognitive Psychology (ESCoP) in Tenerife, Spain. (2019)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Identification of the second of two targets (T2) is difficult
														when it follows the first one within 200-500 milliseconds.
														This so-called attentional blink (AB) may reflect that a
														missed T2 fails to reach post-perceptual processing. Alternatively,
														T2 may still reach working memory partially, or in
														a degraded fashion. To arbitrate between these possibilities,
														we applied mixture modeling to continuous target features
														(e.g., orientation). If T2 does not reach post-perceptual
														processing, responses should be random guesses, that
														is, uncorrelated with the target. If the T2 representation is
														only degraded, then errors should cluster around the target
														with a certain precision. We observed notable differences
														in AB tasks that are spatially variable and those that
														are not. In non-spatial tasks, T2 identification was binary;
														it either did or did not reach post-perceptual processing. In
														spatial tasks, however, T2 identification was graded, suggesting
														it was represented in working memory, but with
														decreased precision.</p>
                                                    </div>
												</div>	
												
												<div class="item mix cpaper" data-year="2019">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
														<h4 class="pubtitle">Decoding Sensory and Abstract Information From Activity Silent Brain States </h4>
                                                        <div class="pubauthor">Kandemir, G.,  <strong>Karabay, A.</strong>, & Akyürek, E. G.</div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>21st Conference of the European Society for Cognitive Psychology (ESCoP) in Tenerife, Spain. (2019)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Distributed Working Memory (WM) models attribute different
														levels of WM representations to different regions of
														the brain. One highly debated factor is whether the information
														represented in different levels is retained via similar
														mechanisms. Recently it was shown that sensory information
														was maintained in activity-silent form and that the
														state of the network could be revealed following a perturbation
														by the presentation of a non-informative signal (impulse
														signal). We applied the same perturbation technique
														to representations in visual WM, which either corresponded
														to directly presented orientation gratings, or to
														stimuli that were recoded following abstract task rules that
														consisted of rotation instructions. The decoding of EEG recordings
														revealed that abstract task rules were also retained
														in activity-silent form and that the impulse signal
														boosted decoding accuracy during the activity-silent WM
														maintenance phase. Furthermore, the imagined orientations
														that were the product of the rotation task were also
														decodable from impulse-driven activity.</p>
                                                    </div>
												</div>	
												<div class="item mix cpaper" data-year="2019">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">The Acute Effects Of Cocoa Flavanols On Visual Working Memory </h4>
                                                        <div class="pubauthor">Altınok, A., <strong>Karabay, A.</strong>, & Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>21st Conference of the European Society for Cognitive Psychology (ESCoP) in Tenerife, Spain. (2019)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Consumption of cocoa flavanols may have beneficial physiological
														effects on the brain due to their ability to activate
														nitric oxide synthesis. Nitric oxide mediates vasodilation,
														increasing cerebral blood flow, and can also act as a neurotransmitter.
														However, the cognitive consequences of cocoa
														flavanols remain underspecified. The aim of this study
														was to examine whether cocoa flavanols influence visual
														working memory (WM). We conducted two randomised,
														within-subjects, placebo controlled, double-blind experiments
														on normal healthy adult volunteers (N=48 and
														N=36, gender-balanced). In the first experiment, we measured
														passive maintenance of grating orientations in WM,
														whereas in the second experiment we measured active updating
														of WM (rotation). Precision and guess rates were
														analysed with MemToolBox. The results suggested that
														passive maintenance in visual WM is not enhanced by cocoa
														flavanols, possibly because it relies on activity-silent
														(synaptic) mechanisms. By contrast, preliminary results indicate
														that active updating of WM is affected by cocoa flavanols.</p>
                                                    </div>
												</div>	
												<div class="item mix cpaper" data-year="2019">
													<div class="pubmain">
													<!--<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                    </div>-->
														<h4 class="pubtitle">Decoding Visual Working Memory Before and After Mental Operations </h4>
                                                        <div class="pubauthor">Kandemir, G. <strong>Karabay, A.</strong>, &  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>BCN Winter Meeting at the University of Twente in Twente, Netherlands.(2019)</div>
													</div>
												</div>	
												
												
												<div class="item mix jpaper" data-year="2018">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/article/10.1007/s00213-018-4861-4" class="tooltips" title="link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/content/pdf/10.1007%2Fs00213-018-4861-4.pdf" class="tooltips" title="indir" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<a href="Files/Data/CocoaFlavanolsAttention.zip" class="tooltips" title="veri" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a> 
															<a href="Files/Tasks/CocoaFlavanolsAttention.7z" class="tooltips" title="deney" target="_blank">
                                                                <i class="icon-cogs"></i>
                                                            </a> 
													    </div>
                                                        <h4 class="pubtitle">The acute effects of cocoa flavanols on temporal and spatial attention</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>, Saija, J., Field, D., &  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Psychopharmacology. (2018)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>In this study, we investigated how the acute physiological effects of cocoa flavanols might result in specific cognitive changes, in particular in temporal and spatial attention. To this end, we pre registered and implemented a randomized, double-blind, placeboand baseline-controlled crossover design. A sample of 48 university students participated in the study and each of them completed the experimental tasks in four conditions (baseline, placebo, low dose, and high-dose flavanol), administered in separate sessions with a 1-week washout interval. A rapid serial visual presentation task was used to test flavanol effects on temporal attention and integration, and a visual search task was similarly employed to investigate spatial attention. Results indicated that cocoa flavanols improved visual search efficiency, reflected by reduced reaction time. However, cocoa flavanols did not facilitate temporal attention nor integration, suggesting that flavanols may affect some aspects of attention, but not others. Potential underlying mechanisms are discussed.</p>
                                                    </div>
                                                </div>
											
												<div class="item mix cpaper" data-year="2017">
													<div class="pubmain">
													
														<h4 class="pubtitle">The Acute Effects of Cocoa Flavanols on Temporal and Spatial Attention </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>, Saija J., David F., &  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>winter conference 2017 of De Nederlandse Vereniging voor Psychonomie in Egmond, Netherlands. (2017)</div>
													</div>
												</div>
												
												<div class="item mix cpaper" data-year="2018">
													<div class="pubmain">
													<div class="pubassets">
                                                            
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            
                                                    </div>
														<h4 class="pubtitle">Target Color and Contrast Influences Temporal Attention in Rapid Serial Visual Presentations </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>&  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>20th Conference of the European Society for Cognitive Psychology (ESCoP) in Potsdam, Germany. & 40th European Conference on Visual Perception (ECVP) in Berlin, Germany. (2017) & Psychonomics International Meeting in Amsterdam. (2018) </div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Attentional blink (AB) is a phenomenon that identifying the second target (T2) stimulus is restricted when it follows the first target (T1) with a short interval (200-500 ms). Various factors modulate AB; in this study, we investigated how target (I) colors and (II) contrast influence temporal attention. Attentional blink/temporal integration task was adapted to study in order to test how different color/contrast pairs influence T2| T1 accuracy and temporal integration. There were two color/contrast conditions: single color/contrast (T1 and T2 colors/contrast matched), mixed color/contrast (T1 and T2 were different colors/contrast). (I) It is found that T2| T1 accuracy were higher in single color condition. Further color specific analysis showed that T1 and T2 accuracy was high when target color was red and T2| T1 identification was greater when T2 color was red. Moreover, greater integration was observed in mixed color condition. It is a surprising finding since targets did not contain multiple colors in any trials. (II) There was no difference between single and mixed contrast condition on T2| T1 accuracy and temporal integration. Greater T1 and T2 accuracy was observed when targets were in high contrast condition. Better T2| T1 identification was observed in the high contrast T2 condition. On the contrary, integration was affected by T2 contrast, and more integration was observed when T2 contrast was low. In conclusion, (I) temporal attention was influenced by target color-pair conditions; however (II) contrast condition does not influence temporal attention in the same way color-pairs does.</p>
                                                    </div>
												</div>	
												
												
												<div class="item mix jpaper" data-year="2017">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="https://link.springer.com/article/10.3758%2Fs13414-017-1333-6" class="tooltips" title="link" target="_blank">
                                                                <i class="icon-external-link"></i>
                                                            </a>
                                                            <a href="https://rd.springer.com/content/pdf/10.3758%2Fs13414-017-1333-6.pdf" class="tooltips" title="indir" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
                                                        </div>
                                                        <h4 class="pubtitle">The effects of Kanizsa contours on temporal integration and attention in rapid serial visual presentation</h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong> &   Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-success">Journal Paper</span> Attention, Perception, & Psychophysics. (2017)</div>
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Performance in rapid serial visual presentation tasks has been shown to depend on the temporal integration of target stimuli when they are presented in direct succession. Temporal target integration produces a single, combined representation of visually compatible stimuli, which is comparatively easy to identify. It is currently unknown to what extent target compatibility affects this perceptual behavior, because it has not been studied systematically to date. In the present study, the effects of compatibility on temporal integration and attention were investigated by manipulating the Gestalt properties of target features. Of particular interest were configurations in which a global illusory shape was formed when all stimulus features were present; a Kanizsa stimulus, which was expected to have a unifying effect on the perception of the successive targets. The results showed that although the presence of a Kanizsa shape can indeed enhance temporal integration, this also was observed for other good Gestalts, such as due to common fate and closure. Identification accuracy seemed to vary, possibly as a result of masking strength, but this did not seem associated with attentional processing per se. Implications for theories of Gestalt processing and temporal integration are discussed.</p>
                                                    </div>
                                                </div>
												
												
												<div class="item mix cpaper" data-year="2017">
													<div class="pubmain">
													
														<h4 class="pubtitle">Kanizsa Effects on Temporal Integration and Attention </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>&  Akyürek, E.G. </div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>Heymans symposium at the Rijksuniversiteit Groningen in Groningen, Netherlands. (2017)</div>
													</div>
												</div>	
												
												
												<div class="item mix cpaper" data-year="2015">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>    
													</div>
														<h4 class="pubtitle">Perceptual Grouping by Orientation Coherence </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>& Kurylo, D.</div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>Science Day, Brooklyn College in NY, the US. (2015)</div>
													</div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Perceptual grouping allows the unification of elements within complex visual scenes. Perceptual grouping can be based upon several relationships among stimulus elements, including common orientation. Grouping can be disrupted by introducing noise elements, which disengage binding among target elements. We investigated parameters that limit grouping by interferencefrom noise. Specifically, we determined (1) the level of deviation of noise elements and (2) proportion of noise-target elements required to break perceptual grouping.It was hypothesized that 45° deviation of noise elements is required before disruption is apparent, since 45°borders the level of rotation oriented towards an opposing grouping pattern. It was further hypothesized that stimuli exceeding 50% noise elements will disrupt perceptual grouping, since the dominant grouping pattern will be carried by noise elements. In order to test these hypotheses, we measured visual discrimination of visual patterns. Four subjects indicated the dominant grouping pattern (horizontal or vertical) of an array of Gabor patches (oriented gratings). Measurements were made at five levels of orientation coherence and six levels deviation of noise elements. Backward masking was used to limit processing time of the stimulus.Results showed that perceptual grouping decreased significantly (from 95% to 67%) in the 45° of deviation condition. With 60% noise elements,discrimination was reduced to chance (52%). These results indicate that noise serves to reverse perceived grouping when presented at magnitudes or proportions that dominate constituents of stimulus patterns.</p>
                                                    </div>
												</div>	
												
												
												<div class="item mix cpaper" data-year="2012">
													
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>    
													</div>
														<h4 class="pubtitle">Istemli & Istemsiz Otobiyografik Anilarda Yasa Bagli Degisimler (Variations of Voluntary and Involuntary Autobiographical Memories Depending on Age) </h4>
                                                        <div class="pubauthor">Er N.,<strong>Karabay, A.</strong>, Kaynar G., Uysal M. M., &  Boyraz F. U.</div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>17th National Psychology Congress in Istanbul, Turkey. (2012)</div>
                                                    </div>
													<div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Otobiyografik bellek, kişinin geçmiş yaşam olaylarına ve yaşantılarına ait belleğidir. Otobiyografik anıların niteliksel özelliklerini ortaya çıkarmaya yönelik yapılan çalışmalara bakıldığında; farklı bazı çalışma yöntemleri olduğunu görmekteyiz. En yaygın kullanılan çalışma yöntemlerinin başında, kişiye bir ipucunun verildiği ve bu ipucu doğrultusunda kişinin istemli olarak bir anısına gittiği çalışmalar gelmektedir. Oysa günlük yaşamımızda, hatırlamak için özel bir çaba sarf etmediğimiz birçok otobiyografik anının da zihnimize çıktığı bilinmektedir. Hatırlamak için özel bir çaba göstermediğimiz istemsiz anıların istemli anılardan farklı özellikler taşıdığına ilişkin ilk bilgiler Ebbinghaus’a dayanmaktadır. Ancak Berntsen (1998)’in de ifade ettiği gibi, bu ayrım otobiyografik bellek araştırmalarında sık sık göz ardı edilmiştir. Buna neden olarak gösterilen açıklamalardan biri; istemsiz anıların, günlük yaşamda iyi bilinen bir fenomen olarak görünmesine karşın araştırılması oldukça zor bir kavram olmasıdır. İstemsiz otobiyografik anılar konusundaki ilk sistematik bulgular, Bernsten (1996b)’in günlük çalışmalarından gelmektedir. İstemsiz anılar konusunda yapılan çalışmalara bakıldığında, en yaygın kullanılan yöntemin, gün içinde zihne çıkan istemsiz anıların kaydedilmesi olduğu görülmektedir. Anıların belirli bir süre boyunca, günlük olarak kaydedilmesi süreklilik gerektiren bir yöntem olması nedeniyle uygulaması oldukça güç olan bir araştırma yöntemidir. İstemsiz anılar için alternatif olarak kullanılan yeni araştırma yöntemlerinden biri de bilgisayar uygulamalarıdır. Bu uygulamalarda, katılımcıdan bilgisayar başında yapmakta olduğu bir işe odaklanması istenmektedir. Genelde rutin ve basit olarak seçilen bu görevler sırasında, katılımcının zihninin görev dışındaki bazı düşünce ve anılara kayması beklenmektedir. Bu sırada kişilerin akıllarına gelen anıların, istemsiz olarak zihne çıkan anılar olacağı düşünülmektedir. İstemi anılar için yürütülen bilgisayar görevinde ise katılımcılara bir hedef gösterilmekte ve kendisine verilen hedefler doğrultusunda, istemli anılara gitmeleri istenmektedir.</p>
														<p>Böylelikle bu çalışmada istemli ve istemsiz otobiyografik anı özelliklerinin, son yıllarda daha sıkça kullanılmaya başlanan (Schlagman ve Kvavilashvili, 2008) “bilgisayar uygulaması yöntemi” ile araştırılması hedeflenmektedir. Bu doğrultuda iki aşamalı bir süreç izlenmektedir. Öncelikle katılımcılar bilgisayar ortamında hazırlanmış iki farklı ara faaliyet görevi ile karşılaşmaktadırlar. Bu aşamada verilen yönergede katılımcıya ‘yapacağı türden görevler sırasında zaman zaman dikkatinin dağılabileceği ve aklına farklı düşünceler ya da anılar gelebileceği’ ifade edilmektedir. Temelde şekil ve renklerin eşleştirilmesine dayanan bu görevler sırasında katılımcının aklına bir anısının gelmesi durumunda, bilgisayar ortamındaki görevi durdurarak aklına gelen anıyı not etmesi belirtilmektedir. Katılımcının bilgisayar ortamındaki bu ilk aşamayı tamamlaması ile birlikte, ikinci aşama olan istemli anı aşamasına geçilmektedir. Aynı şekilde istemli anı uygulamasında da katılımcılara üç farklı kategoride bulunan 18 kelime bilgisayar ekranından gösterilmektedir. İlişkiler kategorisi, yaşantı kategorisi ve duygu kategorisi olmak üzere üç temel kategorinin her birinde 6 kelime bulunmaktadır. Katılımcılardan, bu üç ilişki kategorisini temsil eden birer kelime seçerek, toplam 3 istemli anı aktarmaları istenmektedir. Böylelikle uygulama sonunda her katılımcıdan en az 3 istemli ve 1 istemsiz anı elde edilmektedir. Araştırmada kullanılan kelimelerin seçiminde kelime frekansı bilgisi ve literatürde yapılan benzer çalışmalar temel alınmıştır.  Çalışmada farklı yaş gruplarından 175 katılımcıya ulaşılmış, uygulamasında eksikler bulunan katılımcıların verileri dışarıda tutularak farklı yaş gruplarından gelen toplam 154 kişinin verisi analizlere dahil edilmiştir. Elde edilen bulgular ilgili literatür temelinde tartışılmıştır.</p>
                                                    </div>
                                                </div>
											
												<div class="item mix cpaper" data-year="2012">
													<div class="pubmain">
														<h4 class="pubtitle">Autobiography Of Aging Mind: Age Related Effects On Voluntary And Involuntary Autobiographical Memories </h4>
                                                        <div class="pubauthor">Er N.,<strong>Karabay, A.</strong>, Kaynar G., Uysal M. M., &  Boyraz F. U.</div>
                                                        <div class="pubcite"><span class="label label-warning">Poster</span>IX International Cognitive Neuroscience Meeting in Istanbul, Turkey. (2012) </div>
                                                    </div>
                                                </div>
											
											
												<div class="item mix cpaper" data-year="2009">
													<div class="pubmain">
													<div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>    
                                                    </div>
														<h4 class="pubtitle">Engellenme Karsisinda Verilen Tepkiler Ile Kisilik Tiplerinin Ve Yukleme Cesitlerinin Iliskisi (The Relationship between Frustration Responses, Personality Types and Attribution) </h4>
                                                        <div class="pubauthor"><strong>Karabay, A.</strong>&  Cakmak, M.A.</div>
                                                        <div class="pubcite"><span class="label label-warning">Talk</span>14. Ulusal Psikoloji Ogrencileri Kongresi (14th Conference of National Psychology Students) in Istanbul, Turkey. (2009)</div>    
                                                    </div>
                                                    <div class="pubdetails">
                                                        <h4>Abstract</h4>
                                                        <p>Bu araştırmada, A ve B tipi bireylerin öfke düzeylerinin karşılaştırılması ve A ve B tipi kişilerin ne yönde atıfta bulunduklarının tespit edilmesi amaçlanmaktadır.Yöntem: Araştırmaya Ankara’daki çeşitli üniversitelerinin değişik bölüm ve sınıflarında öğrenim gören 126 öğrenci katılmıştır. Araştırmada veri toplama araçları olarak Çok Boyutlu Öfke Ölçeği, Yükleme Biçimi Ölçeği ve A Tipi Kişilik Ölçeği kullanılmıştır.Bulgular: Öfke ve atıf puanlarının A Tipi kişilikle olumlu yönde ilişkili olduğu tespit edilmiştir. Bireyler A Tipi kişilik yoğunluğuna göre değerlendirildiğinde ise, genel örneklemden farklı olarak A Tiplerinin öfke ve atıf puanlarını yordadığı görülmüştür. Kişilerin sahip oldukları hedeflerle öfke düzeyleri arasında ilişkiye rastlanmamıştır.Sonuç: Bireyin sahip olduğu kişilik özellikleri, engellenme karşısında ne yönde atıflarda bulunacakları ve öfke düzeyleri ile ilişkilidir. A tipi kişiler engellenme karşısında içsel atıflarda bulunma eğiliminde iken, B tipi kişiler aynı durumlarda dışsal atıfta bulunma eğilimindedirler. </p>
                                                    </div>
                                                </div>
												


                                            </div>
                                        </div>
                                    </div>

                                </div>
                            </div>

                        </div>
                    </div>
                </div>


                <!--<div id="teaching" class="page">
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                
                                <h2 class="title">Teaching</h2>
                                
                                <div class="row">
                                    <div class="col-md-12">
                                        <p>I like to teach, </p>                                                   
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="pagecontents">
                        <div class="section color-1">
                            <div class="section-container">
                                <div class="row">
                                    <div class="title text-center">
                                        <h3>Currrent Teaching</h3>
                                    </div>
                                    <ul class="ul-dates">
                                        <li>
                                            <div class="dates">
                                                <span>Present</span>
                                                <span>2017</span>
                                            </div>
                                            <div class="content">
                                                <h4>Honors Research Practicum</h4>
                                                <p>In this course, I and three honors student of the psychology (BA) students do a research project. The aim of the study is to show students how to do a research step by step. </p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>Present</span>
                                                <span>2003</span>
                                            </div>
                                            <div class="content">
                                                <h4>SELC 8160 Molar Endodontic Selective</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>Present</span>
                                                <span>2010</span>
                                            </div>
                                            <div class="content">
                                                <h4>Endodontics Postdoctoral AEGD Program</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <div class="section color-2">
                            <div class="section-container">
                                <div class="row">
                                    <div class="title text-center">
                                        <h3>Teaching History</h3>
                                    </div>
                                    <ul class="ul-dates-gray">
                                        <li>
                                            <div class="dates">
                                                <span>1997</span>
                                                <span>1995</span>
                                            </div>
                                            <div class="content">
                                                <h4>Preclinical Endodnotics</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>2005</span>
                                                <span>2003</span>
                                            </div>
                                            <div class="content">
                                                <h4>SELC 8160 Molar Endodontic Selective</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>2011</span>
                                                <span>2010</span>
                                            </div>
                                            <div class="content">
                                                <h4>Endodontics Postdoctoral AEGD Program</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>2011</span>
                                                <span>2010</span>
                                            </div>
                                            <div class="content">
                                                <h4>Endodontics Postdoctoral AEGD Program</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                        <li>
                                            <div class="dates">
                                                <span>2011</span>
                                                <span>2010</span>
                                            </div>
                                            <div class="content">
                                                <h4>Endodontics Postdoctoral AEGD Program</h4>
                                                <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed ultrices ac elit sit amet porttitor. Suspendisse congue, erat vulputate pharetra mollis, est eros fermentum nibh, vitae rhoncus est arcu vitae elit.</p>
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>-->
                
                <!--<div id="gallery" class="page">
                    <div class="pagecontents">
                        
                        <div class="section color-3" id="gallery-header">
                            <div class="section-container">
                                <div class="row">
                                    <div class="col-md-3">
                                        <h2>Gallery</h2>
                                    </div>
                                    <div class="col-md-9">
                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="section color-3" id="gallery-large">
                            <div class="section-container">
                                
                                <ul id="grid" class="grid">
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/450x600.png">
                                            <a href="img/gallery/450x600.png" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/600x600.png">
                                            <a href="img/gallery/600x500.png" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/900x600.png">
                                            <a href="img/gallery/900x600.png" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/400x300.png">
                                            <a href="img/gallery/400x300.png" class="popup-with-move-anim"> 
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/400x300.png">
                                            <a href="img/gallery/400x300.png" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <i class="icon-search"></i>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    <li>
                                        <div>
                                            <img alt="image" src="img/gallery/800x600.png">
                                            <a href="img/gallery/800x600.png" class="popup-with-move-anim">
                                                <div class="over">
                                                    <div class="comein">
                                                        <h3>Image Title</h3>
                                                        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
                                                        <div class="comein-bg"></div>
                                                    </div>
                                                </div>
                                            </a>
                                        </div>
                                    </li>
                                    
                                    
                                </ul>
                                    
                            </div>
                        </div>
                    </div>
                    
                </div>-->
				
				
				
				<div id="experiments" class="page">
					<div class="row2">
						<div id="rightlinks">
							<a href="indexTR.html">TR</a> 
							<a href="index.html">EN</a> 
						</div>	
					</div>
                    <div class="pageheader">
                        
                        <div class="headercontent">
							<div class="page-container">
								<div class="section-container">
									<h3 class="title">Görevler</h3>
								</div>
							
							
							
                            <div class="section color-2" id="pub-grid">
                                <div class="section-container">
                                    <div class="row">
                                        <div class="col-md-12">
                                            <div class="pitems">
												
											<!--Tasks format below-->
												<!--Tasks in the format below-->
												<!--Tasks in the format below-->
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="/Files/Tasks/VisualSearchTask.osexp" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
														
															<!--<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a>-->
													    </div>
														<img alt="image" src="img/experiments/VS.gif" align="left" style="padding:0 20px 20px 0;" width=250, height = 220>
														    <h3><b>Sıralı görsel arama </b></h3>
                                                            <p>Görsel arama görevleri, insanların karmaşık görsel ortamlarda belirli nesneleri veya özellikleri aradıkları
															yaygın bir yoldur. Özellikle seri görsel arama görevleri, hedef nesne veya özelliğin bulunana kadar bir görsel 
															ekranı sıralı veya lineer şekilde tarayarak bir görsel arama türünü ifade eder. Seri görsel arama görevinde, 
															katılımcılar genellikle görsel ekrandaki belirli bir konumda başlar ve hedefi bulana kadar kalan bölümleri 
															sistematik bir şekilde tararlar. Seri görsel arama görevleri, ekranındaki öğelerin sayısı, hedef ve dikkat 
															dağıtıcı öğeler arasındaki benzerlik gibi bir dizi faktörden etkilenebilir.
															</p>
													</div>
                                                    
                                                    <div class="pubdetails">
														<h4><b>Görev Detayları</b></h4> 
                                                        <p> Bu görev Altinok ve ark. (2023) çalışmasında kullanılmıştır. Makalede gerekli tüm ayrıntılarını bulabilirsiniz.
															SGA görevi 30 uygulama ve 300 deneyimsel deneme (her koşul için 100 deneme) ve 10 blok içerir. Her blok 30 denemeden
															oluştu ve katılımcılara bloklar arasında ara verme izni verildi. Her bloğun ilk denemesi, katılımcıların boşluk çubuğuna
															bastığı anda başlar. Sabitleme noktası 300-500ms gösterildikten sonra arama dizisi 1000ms boyunca sunulur ve 1000ms 
															sonrasında bir maske ile kapatılır. Arama dizisi her zaman tek bir hedef harf içerir ve 14, 20 veya 26 çeldirici ile birlikte
															gösterilir. Katılımcılara hedef harfin (T) yönelimini mümkün olan en hızlı ve doğru şekilde bildirmeleri talimatı verilir.
															Katılımcılar, yanıtlarını vermek için klavyedeki ok tuşlarını kullanarak maske kapanana kadar, yani toplamda 2000 ms'ye kadar
															süreye sahiptiler. Yanıtlar, klavyedeki ok tuşlarıyla kullanarak verilir. Yanıttan sonra, katılımcılar doğruluğuna bağlı 
															olarak mutlu veya mutsuz bir gülümseme ile 175ms geribildirim aldılar. Geribildirimi takip eden 250-300 ms'lik bir ara 
															dönemden sonra bir sonraki deneme başlar.
														</p>
														<p><u>Bağımsız değişken:</u> Çeldirici sayısı, 14,20,26</p>
														<p><u>Bağımlı değişken:</u> Doğruluk, Tepki süresi</p>
														
														<p><i>Bu dikkat görevini kullanmaktan çekinmeyin ama lütfen atıfta bulunmayı unutmayın!</i></p>
														<img alt="image" src="img/experiments/VS.png" width=500 >
														<p></p>
														<p></p>
														<p></p>
														<h4><b>Referanslar</b></h4>
														<p>Altınok, A., Karabay, A., Balta, G, de Jonge, J., & Akyürek, E.G. (2023). The effects of gamma-aminobutyric
														acid (GABA) on working memory and attention: A randomised, double-blind, placebo-controlled, crossover
														trial. </i>Journal of Psychopharmacology. </i> doi: 10.1177/02698811231161579
														</p>
														
														<p>Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences.
														<i>Behavior Research Methods, 44</i>(2), 314-324. doi:10.3758/s13428-011-0168-</p>

                                                    </div>
                                              
												</div> 
												
												
												
												
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="/Files/Tasks/hybridRSVP.osexp" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
														
															<!--<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a>-->
													    </div>
														<img alt="image" src="img/experiments/AB-integration.gif" align="left" style="padding:0 20px 20px 0;" width=250>
														    <h3><b>Hibrit HSGS -<i>Zamansal Birleştirme & Dikkat Sekmesi Görevi</i></b></h3>
                                                            <p> Dikkat sekmesi (DS) ikinci hedefin ilk hedefi 200-500 ms arasında takip ettiği durumlarda, ikinci hedefin
															tanımlanabilmesindeki güçlüğü gösteren bir fenomendir(Raymond, Shapiro, & Arnell, 1992). DS genellikle hızlı 
															seri görsel sunum (HSGS) görevleri ile test edilir. Bu görevlerde bir ya da iki hedef vardır va katılımcıların
															hedefleri çeldiricilerin arasından raporlamaları istenir. Hedeflerin arasında çeldirici olmadığı durumlarda 
															iki hedef aynı algısal episoda düşebilir. Bu fenomen ise Hommel ve Akyurek (2005) tarafından zamansal birleştirme
															olarak tanımlanmıştır. Bu hibrit görev ile zamasal birleştirme sıklığı ve DS miktarı tek bir görev ile ölçümlenebilir.
															</p>
													</div>
                                                    
                                                    <div class="pubdetails">
														<h4><b>Görev Detayları</b></h4> 
                                                        <p> Bu hibrit görevin bir benzerini uyarıcı özelliklerindeki değişimin zamansal hedef tanımadaki etkisini ölçen bir araştırmada
														kullandık (Karabay & Akyurek, 2019). Bu görev dikkat performansını ölçmek için kullanılabilir. Toplamda 7 farklı hedefin olduğu
														bu görevde katılımcılara her denemede çeldiricilerin arasında bir ya da iki tane hedef gösterilir. Katılımcıların deneme sonunda
														bu iki hedefi de doğru sıra ile raporlamaları istenir. Görevin detaylarını Karabay ve Akyürek (2019) da bulabilirsiniz. Bu görev 
														ve refere edilen görevin tek farkı, bu görevde hedeflerin rengi yalnızca mavidir. 24 adet pratik denemesi ve 340 adet deneysel
														deneme olan bu görev yaklaşık 45 dakikada tamamlanabilmektedir.
														<a href="https://osdoc.cogsci.nl/3.3/download/" target="_blank">Open Sesame</a> kullanılarak programlanmıştır.
														Hedefleri klavyenin numpad bölümüne yapıştırabilirsiniz. Her bir hedef tipinin doğru cevabı deneyin içerisinde dosya gezgini
														içerisinde bulunmaktadır. 

														</p>
														<p><u>Bağımsız Değişkenler:</u> Gecikme, 1,3,8</p>
														<p><u>Bağımlı Değişkenler:</u> T1 performansı, T2|T1 performansı, zamansal birleştirme, sıra hatası</p>
														
														<p><i>Bu hibrit HSGS görevini kullanmaktan çekinmeyin ama lütfen atıfta bulunmayı unutmayın!</i></p>
														<img alt="image" src="img/experiments/DualRSVP.png" width=500 >
														<p></p>
														<p></p>
														<p></p>
														<h4><b>Referanslar</b></h4>
														<p>
														Karabay, A. & Akyürek, E. G. (2019). Temporal integration and attentional selection of color
														and contrast target pairs in rapid serial visual presentation. <i>Acta Psychologica, 196</i>, 56–69.
														doi:10.1016/j.actpsy.2019.04.002</p>
														<p>
														Akyürek, E. G., Eshuis, S. A. H., Nieuwenstein, M. R., Saija, J. D., Başkent, D., & Hommel, B. (2012). Temporal target integration 
														underlies performance at Lag 1 in the attentional blink. <i>Journal of Experimental Psychology: Human Perception and Performance, 
														38</i>(6), 1448–1464. doi:10.1037/a0027610
														</p>
														<p>
														Raymond, J. E., Shapiro, K. L., & Arnell, K. M. (1992). Temporary suppression of visual processing in an 
														RSVP task: An attentional blink? <i>Journal of Experimental Psychology: Human Perception and Performance, 18</i>, 
														849–860. doi:10.1037/0096-1523.18.3.849
														</p>
														<p>
														Hommel, B., & Akyurek, E. G. (2005). Lag-1 sparing in the attentional blink: Benefits and costs of integrating two
														events into a single episode. <i>The Quarterly Journal of Experimental Psychology, 58A</i>(8), 1415–1433. 
														doi:10.1080/02724980443000647										
														</p>														
														<p>Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences.
														<i>Behavior Research Methods, 44</i>(2), 314-324. doi:10.3758/s13428-011-0168-</p>
														
                                                    </div>
                                              
												</div> 	
											
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="/Files/Tasks/DT_CLAB.osexp" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
														
															<!--<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a>-->
													    </div>
														<img alt="image" src="img/experiments/DTCLAB.gif" align="left" style="padding:0 20px 20px 0;" width=250>
														    <h3><b>Dwell Time Paradigmasi</b></h3>
                                                            <p> Dwell time (DT) paradigmasi ilk olarak Duncan, Ward ve Shapiro (1994) tarafından kullanılmıştır. Bu
															görevde, dikkatin bir lokasyondan başka bir lokasyona zaman içinde geçişi test edilir. Dikkat sekmesi 
															görevinde olduğu gibi iki hedef arasında yarım saniyeden daha az bir süre olduğunda ikinci hedefin
															kodlanmasında hatalar olur. Bu deneyde rengi tekrar yapma görevini DT paradigmasına uygulayarak 
															çalışma belleği modellerini DT paradigmasında uyguladık (Karabay et al., in press).
															</p>
													</div>
                                                    
                                                    <div class="pubdetails">
														<h4><b>Görev Detayları</b></h4> 
                                                        <p> Bu görev Karabay ve arkadaşlarının (in press) deney 2Bsidir. Bu görevi kullanarak görsel farkındalığın doğası hakkında
															araştırma yürüttük. Bu görev, dikkatin bekleme süresini ölçmek ve işlenen görsel bilginin çalışma belleği modelleri 
															kullanılmasına olanak tanır. CIELAB renk çemberinden 2 farklı renk iki hedef olarak rastgele seçilir ve katılımcıların
															bu iki hedef rengi tekrar oluşturmaları sorulmuştur. Görev 60-75 dakika arası sürmektedir. Deney
														<a href="https://osdoc.cogsci.nl/3.3/download/" target="_blank">Open Sesame</a> kullanılarak programlanmıştır. 
														<p>
														<i> Not: </i> Bu görev Pythonun colur ve colormath kütüphaneleri ile çalışmaktadır. Bu nedenle eğer bu görevi kullanmak isterseniz
														OpenSesame'yi yönetici olarak çalıştırıp debug penceresinde aşağıdaki kodu çalıştırmanız gerekir. 
														<p></p>
														<code>
														<p>import pip</p>
														<p>pip.main(['install', 'colormath'])</p>
														<p>pip.main(['install', 'colour'])</p>
														</p>
														</p>
														</code>
														<p><u>Bağımsız değişkenler:</u> SOA, 250 ms, 800 ms</p>
														<p><u>Bağımlı değişkenler:</u> Hedef 1 tekrar yapma hatası, hedef 2 tekrar yapma hatası</p>
														
														<p><i>Bu DT görevini kullanmaktan çekinmeyin ama lütfen atıfta bulunmayı unutmayın!</i></p>
														<img alt="image" src="img/experiments/DTCLAB.png"  >
														<p></p>
														<p></p>
														<p></p>
														<h4><b>Referanslar</b></h4>
														<p>
														Karabay, A., Wilhelm, S. A., de Jonge, J., Wang, J., Martens, S., & Akyürek, E. G. (in press). Two faces of
														perceptual awareness during the attentional blink: Gradual and discrete. <i>Journal of Experimental
														psychology: General</i>. doi:10.1037/xge0001156</p>
														<p>Duncan, J., Ward, R., & Shapiro, K. (1994). <i>Direct measurement of attentional dwell time in human vision. Nature, 369</i>(6478), 313–315. doi:10.1038/369313a0</p>

														<p>Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences.
														<i>Behavior Research Methods, 44</i>(2), 314-324. doi:10.3758/s13428-011-0168-</p>

                                                    </div>
                                              
												</div>
																
											<!--Tasks format below-->
	
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="/Files/Tasks/VWM.osexp" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
															<!--<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a>--> 
													    </div>
														<img alt="image" src="img/experiments/WM_task.gif" align="left" style="padding:0 20px 20px 0;" width=250>
														    <h3><b>Görsel Çalışma Belleği - <i>Yönü Tekrar Yapma Görevi</i></b></h3>
                                                            <p> Çalışma belleği (ÇB) bilginin kısa sürede tutulduğu ve manipüle edilebildiği bellektir. ÇB'yi açıklayan
																birden çok kavramsal, nöral ve matematiksel modeller mevcuttur. Yönü tekrar yapma görevi çalışma belleğinin
																kapasitesini keskin bir şekilde ölçebilen bir görevdir. Bu görevin en güçlü yanlarından birisi çalışma 
																belleğinde tutulan bilgilerin netliğini iki yönlü yerine devamlı bir şekilde tutabilmesidir. Bunun dışında,
																bu görev aracılığı ile çalışma belleği tahmin oranı (guess rate) ve bellek keskinliği (precision) hesaplanabilir.
															</p>
													</div>
                                                    
                                                    <div class="pubdetails">
														<h4><b>Görev Detayları</b></h4> 
                                                        <p> Bunun bir benzeri olan bir ÇB görevini kakao flavanollarının görsel ÇB'ye olan etkilerini incelediğimiz bir araştırma
														projesinde kullandık (Altınok, Karabay,& Akyürek, in prep). Detaylar için araştırmayı okuyabilirsiniz. Bu görevi kullanarak
														ÇB kapasitesi, performansı ve keskinliği gibi ÇB'ye dair değişkenleri farklı ÇB yükleme kondüsyonlarında
														test edebilirsiniz. Kısa bir süre gösterilen sabitleme noktasından sonra, bellek dizisi ekranda 250 ms olarak belirir. ÇB
														yükleme kondüsyonuna bağlı olarak 1 ve 4 arasında yön bilgisi içeren objeler ekranın merkezine 100 piksel
														uzaklıkta belirir. Katılımcılara bu objelerin yönlerinin tutulması sorulmuştur. Takip eden 1 saniyelik hafızada tutma
														süresinden sonra katılımcılara gördükleri objelerden rastgele bir tanesini tekrar oluşturması sorulmuştur. 16 pratik denemesi ve
														240 deneysel denemeden oluşan bu görev 20 ila 30 dakika arasında tamamlanabilmektedir. Deney
														<a href="https://osdoc.cogsci.nl/3.3/download/" target="_blank">Open Sesame</a> kullanılarak programlanmıştır.
														</p>
														<p><u>Bağımsız Değişkenler:</u> ÇB yükleme kondüsyonları, 1,2,3,4</p>
														<p><u>Bağımlı Değişkenler:</u> Tekrar oluşturma hatası</p>
														
														<p><i>Bu ÇB görevini kullanmaktan çekinmeyin ama lütfen atıfta bulunmayı unutmayın!</i></p>
														<img alt="image" src="img/experiments/WMtask.png"  >
														<p></p>
														<p></p>
														<p></p>
														<h4><b>Referanslar</b></h4>
														<p>
														Altinok, A., Karabay, A., & Akyurek, E. G. (2020). Acute effects of cocoa flavanols on visual working memory: No evidence from two randomised, 
														double-blind, baseline- and placebo-controlled, crossover trials. <i>[under review]</i>.</p> 
																												
														<p>Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences.
														<i>Behavior Research Methods, 44</i>(2), 314-324. doi:10.3758/s13428-011-0168-</p>
														
                                                    </div>
                                              
												</div> 
												
												
												
												<!--Tasks in the format below-->	
												
												<div class="item mix jpaper" data-year="2020">
                                                    <div class="pubmain">
                                                        <div class="pubassets">
                                                            <a href="#" class="pubcollapse">
                                                                <i class="icon-expand-alt"></i>
                                                            </a>
                                                            <a href="/Files/Tasks/Stroop_TR.osexp" class="tooltips" title="Download" target="_blank">
                                                                <i class="icon-cloud-download"></i>
                                                            </a>
														
															<!--<a href="https://osf.io/2dp6e/" class="tooltips" title="Data" target="_blank">
                                                                <i class="icon-bar-chart"></i>
                                                            </a>-->
													    </div>
														<img alt="image" src="img/experiments/Stroop_task_TR.gif" align="left" style="padding:0 20px 20px 0;" width=250 height=210>
														    <h3><b>Stroop Görevi</b></h3>
                                                            <p> Stroop efekti çok iyi araştırılmış ve John Ridley Stroop tarafından 1935 yılında bulunmuş bir fenomendir.
															Bu fenomeni kullanarak binlerce araştırma sorusu cevaplanmıştır. Bu görev seçici dikkat kapasitesini ve 
															bilgi işleme hızını ölçer. Katılımcılara renk isimlerinin yazıldığı metinlerin renklerini en kısa sürede
															raporlamaları istenir. Bu görevde renk ismi ile bu ismin yazılı olduğu renk uyuştuğu zaman (uyumlu kondüsyon)
															renk ismi ile bu ismin yazılı olduğu renk uyuşmadığı zamana göre (uyumsuz kondüsyon) daha hızlı cevap verdikleri 
															gözlemlenmiştir. 
															</p>
													</div>
                                                    
                                                    <div class="pubdetails">
														<h4><b>Görev Detayları</b></h4> 
                                                        <p> Katılımcılardan metinlerin rengini en kısa sürede klavye aracılığı ile raporlamaları istenir. Bu deney sekiz bloktan
														oluşmuştur ve her bir blokta 16 deneme mevcuttur. Kırmızı, mavi, yeşil ve sarı olmak üzere dört renk kullanılmıştır. Örneğin:
														</p>
														<p><b>Uyumlu Kondüsyon</b></p>
														<p> <b style="color:red;"> KIRMIZI </b>  ~ Metin rengi kırmızı olduğu için 'k' tuşuna basınız.</p>
														<p> <b style="color:blue;"> MAVİ </b> ~ Metin rengi mavi olduğu için 'm' tuşuna basınız.</p>
														<p> <b style="color:#fff700;"> SARI </b> ~ Metin rengi sarı olduğu için 's' tuşuna basınız.</p>
														<p> <b style="color:green;"> YEŞİL </b> ~ Metin rengi yeşil olduğu için 'y' tuşuna basınız.</p>
														<p><b>Uyumsuz Kondüsyon</b></p>
														<p> <b style="color:green;"> KIRMIZI </b> ~ Metin rengi yeşil olduğu için 'y' tuşuna basınız.</p>
														<p> <b style="color:red;"> MAVİ </b> ~ Metin rengi kırmızı olduğu için 'k' tuşuna basınız.</p>
														<p> <b style="color:blue;"> SARI </b> ~ Metin rengi mavi olduğu için 'm' tuşuna basınız.</p>
														<p> <b style="color:#fff700;"> YEŞİL </b> ~ Metin rengi sarı olduğu için 's' tuşuna basınız.</p>
														<p><u>Bağımsız Değişkenler:</u> Uyumluluk: Uyumlu, Uyumsuz</p>
														<p><u>Bağımlı Değişkenler:</u> Doğruluk, Tepki Süresi</p>
														
														<p><i>Bu dikkat görevini kullanmaktan çekinmeyin ama lütfen atıfta bulunmayı unutmayın!</i></p>
														<img alt="image" src="img/experiments/Strooptask.png"  >
														<p></p>
														<p></p>
														<p></p>
														<h4><b>Referanslar</b></h4>
														<p>
														Stroop, J. R. (1935). Studies of interference in serial verbal reactions. <i>Journal of Experimental Psychology, 18</i>
														(6), 643–662. doi:10.1037/h0054651
														</p> 
														
														<p>Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences.
														<i>Behavior Research Methods, 44</i>(2), 314-324. doi:10.3758/s13428-011-0168-</p>
														
                                                    </div>
                                              
												</div> 
												
								
												
												</div>		
                                            </div>
                                        </div>
                                    </div>

                                </div>
                            </div>

                  

						</div>		
					</div>
                      
					
                </div>
				
				
                <div id="contact" class="page stellar">
					<div class="row2">
						<div id="rightlinks">
							<a href="indexTR.html">TR</a> 
							<a href="index.html">EN</a> 
						</div>	
					</div>
                    <div class="pageheader">
                        <div class="headercontent">
                            <div class="section-container">
                                
                                <h2 class="title">İletişim</h2>
                            
                                <div class="row">
                                    <div class="col-md-8">
                                        <p> Araştırmalarım ve çalışma konularım hakkında bir sorunuz olduğunda ya da bir projenizde benimle çalışmak isterseniz lütfen iletişime geçiniz.  </p>                              
                                    </div>
                                    <div class="col-md-4">
                                        <ul class="list-unstyled">
                                            <li>
                                                <strong><i class="icon-phone"></i>&nbsp;&nbsp;</strong>
                                                <span>ofis: +31 50 36 36657</span>
                                            </li>
                                            <li>
                                                <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
                                                <span>a. karabay@ nyu.edu (boşlukları siliniz)</span>
                                            </li>
                                            <li>
                                                <strong><i class="icon-skype"></i>&nbsp;&nbsp;</strong>
                                                <span>aytac kara bay (boşlukları siliniz)</span>
                                            </li>
                                            <li>
                                                <strong><i class="icon-twitter"></i>&nbsp;&nbsp;</strong>
                                                <span><a href="https://twitter.com/aytckrby" target="_blank">aytckrby</a></span>
                                            </li>
                                            <li>
                                                <strong><i class="icon-linkedin-sign"></i>&nbsp;&nbsp;</strong>
                                                <span><a href="https://www.linkedin.com/in/ayta%C3%A7-karabay-306252a2" target="_blank">aytackarabay</a></span>
                                            </li>
                                        </ul>    

                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                </div>
                
                <div id="overlay"></div>
            
            </div>
        </div>
		<!-- Default Statcounter code for personal website
		http://www.aytackarabay.com -->
		<script type="text/javascript">
		var sc_project=11668669; 
		var sc_invisible=1; 
		var sc_security="ff612015"; 
		</script>
		<script type="text/javascript"
		src="https://www.statcounter.com/counter/counter.js"
		async></script>
		<noscript><div class="statcounter"><a title="Web Analytics
		Made Easy - StatCounter" href="http://statcounter.com/"
		target="_blank"><img class="statcounter"
		src="//c.statcounter.com/11668669/0/ff612015/1/" alt="Web
		Analytics Made Easy - StatCounter"></a></div></noscript>
		<!-- End of Statcounter Code -->
    </body>
</html>
